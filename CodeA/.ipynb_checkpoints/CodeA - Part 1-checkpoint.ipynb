{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "26c0c361",
   "metadata": {},
   "source": [
    "# Sentiment Analysis Assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8d17a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "#I acknowledge that this work is my own, and I have\n",
    "#used ChatGPT 3.5 (OpenAI, https://chat.openai.com/) to rectify few of my errors in the code and also in\n",
    "#some places where I had doubts in the code\n",
    "#and also to help me produce some of the code for Naive Bayes from scratch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "39f58e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Codes Adapted from:\n",
    "#1. Loading the data : https://github.com/HegdeChaitra/IMDB_review_sentiment_analysis/blob/master/exp1.ipynb\n",
    "#2. Tokenization : -> https://github.com/KuWathsala/NLP-Sentiment-Analysis-Beginers-/blob/master/NLP_SA.ipynb\n",
    "#                  -> https://colab.research.google.com/drive/1C5RLXOvaKgbdmeW4PPjg_Q4xooX-r4Oz\n",
    "#                  -> https://colab.research.google.com/drive/1WJ2HEQtwpq7TsGRyV5E1tO6IFGnCbW9A?usp=sharing\n",
    "#3. Frequency Distribution : https://colab.research.google.com/drive/1mkYrOnFt60iDzcH0bhOIP__Us0dvDmlt?usp=sharing#scrollTo=TjTSsQxCvNIF\n",
    "#4. N-Gram : https://spotintelligence.com/2023/04/05/n-grams/\n",
    "#5. Term Weighting (Stopwords,Stemming,TF-IDF) : https://colab.research.google.com/drive/1IsqqtoEVG8n21tb0tUMCN0mLqiBbgnJ8 and also from previous Coursework done in Machine Learning from Ekaterina.\n",
    "#6. Lemmatization : https://www.geeksforgeeks.org/python-lemmatization-with-nltk/\n",
    "#7. Data Splits : https://realpython.com/train-test-split-python-data/\n",
    "#8. Naive Bayes (MultinomialNB) : https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html\n",
    "#9. Naive Bayes - from scratch : https://blog.devgenius.io/implementing-na%C3%AFve-bayes-classification-from-scratch-with-python-badd5a9be9c3\n",
    "#10.Logistic Regression : https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\n",
    "#11.SVM : https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html\n",
    "#12.Evalution (Accuracy, Confusion matrix, Classfication matrix) : https://github.com/ReiCHU31/Sentiment-analysis-of-IMDb-movie-reviews/blob/master/Sentiment%20analysis%20of%20IMDb%20movie%20reviews.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4272c8e",
   "metadata": {},
   "source": [
    "# Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c2b1fcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\shikh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\shikh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#Libraries\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk import ngrams\n",
    "\n",
    "import string\n",
    "import math\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "stoplist = set(nltk.corpus.stopwords.words('english'))\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.lancaster import LancasterStemmer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92328f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading the data adapted from: https://github.com/HegdeChaitra/IMDB_review_sentiment_analysis/blob/master/exp1.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e0efe9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "postive_data_path = \"../CodeA/data/data/pos/\"\n",
    "negative_data_path =\"../CodeA/data/data/neg/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "233d9350",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_files = os.listdir(postive_data_path)\n",
    "for f in range(len(pos_files)):\n",
    "    pos_files[f] = postive_data_path + pos_files[f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "081917e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_files = os.listdir(negative_data_path)\n",
    "for f in range(len(neg_files)):\n",
    "    neg_files[f] = negative_data_path + neg_files[f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dedfa162",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_labels = [1]*len(pos_files)\n",
    "neg_labels = [0]*len(neg_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ac3a11f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=[\"file_names\",\"labels\"])\n",
    "df[\"file_names\"] = pos_files + neg_files\n",
    "df[\"labels\"] = pos_labels + neg_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "882d0f85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4000, 2)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d31114ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_names</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>../CodeA/data/data/pos/10000_8.txt</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>../CodeA/data/data/pos/10008_7.txt</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>../CodeA/data/data/pos/10013_7.txt</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>../CodeA/data/data/pos/10019_8.txt</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>../CodeA/data/data/pos/10020_8.txt</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           file_names  labels\n",
       "0  ../CodeA/data/data/pos/10000_8.txt       1\n",
       "1  ../CodeA/data/data/pos/10008_7.txt       1\n",
       "2  ../CodeA/data/data/pos/10013_7.txt       1\n",
       "3  ../CodeA/data/data/pos/10019_8.txt       1\n",
       "4  ../CodeA/data/data/pos/10020_8.txt       1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aa5d4d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code to get the contents in those .txt files.\n",
    "\n",
    "def get_data(df):\n",
    "    all_txt = []\n",
    "    for i,j in df.iterrows(): #https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.iterrows.html\n",
    "        with open(j[\"file_names\"],'r', encoding='utf-8') as f: #Asked GPT since there was an error loading the data so it suggested to use encoding='utf-8'\n",
    "            txt = f.read()\n",
    "            all_txt.append(txt)\n",
    "#         print(j)\n",
    "    df[\"reviews\"] = all_txt\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6de31aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = get_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6265eca2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_names</th>\n",
       "      <th>labels</th>\n",
       "      <th>reviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>../CodeA/data/data/pos/10000_8.txt</td>\n",
       "      <td>1</td>\n",
       "      <td>Homelessness (or Houselessness as George Carli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>../CodeA/data/data/pos/10008_7.txt</td>\n",
       "      <td>1</td>\n",
       "      <td>You know, Robin Williams, God bless him, is co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>../CodeA/data/data/pos/10013_7.txt</td>\n",
       "      <td>1</td>\n",
       "      <td>Like one of the previous commenters said, this...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>../CodeA/data/data/pos/10019_8.txt</td>\n",
       "      <td>1</td>\n",
       "      <td>When it comes to movies I can be pretty picky,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>../CodeA/data/data/pos/10020_8.txt</td>\n",
       "      <td>1</td>\n",
       "      <td>The legendary Boris Karloff ended his illustri...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           file_names  labels  \\\n",
       "0  ../CodeA/data/data/pos/10000_8.txt       1   \n",
       "1  ../CodeA/data/data/pos/10008_7.txt       1   \n",
       "2  ../CodeA/data/data/pos/10013_7.txt       1   \n",
       "3  ../CodeA/data/data/pos/10019_8.txt       1   \n",
       "4  ../CodeA/data/data/pos/10020_8.txt       1   \n",
       "\n",
       "                                             reviews  \n",
       "0  Homelessness (or Houselessness as George Carli...  \n",
       "1  You know, Robin Williams, God bless him, is co...  \n",
       "2  Like one of the previous commenters said, this...  \n",
       "3  When it comes to movies I can be pretty picky,...  \n",
       "4  The legendary Boris Karloff ended his illustri...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d262101b",
   "metadata": {},
   "source": [
    "# Processing of Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "29cf0960",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cleaning the reviews data "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70b4a139",
   "metadata": {},
   "source": [
    "**Tokenization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0de027f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_names</th>\n",
       "      <th>labels</th>\n",
       "      <th>reviews</th>\n",
       "      <th>tokenized_review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>../CodeA/data/data/pos/10000_8.txt</td>\n",
       "      <td>1</td>\n",
       "      <td>Homelessness (or Houselessness as George Carli...</td>\n",
       "      <td>[homelessness, (, or, houselessness, as, georg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>../CodeA/data/data/pos/10008_7.txt</td>\n",
       "      <td>1</td>\n",
       "      <td>You know, Robin Williams, God bless him, is co...</td>\n",
       "      <td>[you, know, ,, robin, williams, ,, god, bless,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>../CodeA/data/data/pos/10013_7.txt</td>\n",
       "      <td>1</td>\n",
       "      <td>Like one of the previous commenters said, this...</td>\n",
       "      <td>[like, one, of, the, previous, commenters, sai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>../CodeA/data/data/pos/10019_8.txt</td>\n",
       "      <td>1</td>\n",
       "      <td>When it comes to movies I can be pretty picky,...</td>\n",
       "      <td>[when, it, comes, to, movies, i, can, be, pret...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>../CodeA/data/data/pos/10020_8.txt</td>\n",
       "      <td>1</td>\n",
       "      <td>The legendary Boris Karloff ended his illustri...</td>\n",
       "      <td>[the, legendary, boris, karloff, ended, his, i...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           file_names  labels  \\\n",
       "0  ../CodeA/data/data/pos/10000_8.txt       1   \n",
       "1  ../CodeA/data/data/pos/10008_7.txt       1   \n",
       "2  ../CodeA/data/data/pos/10013_7.txt       1   \n",
       "3  ../CodeA/data/data/pos/10019_8.txt       1   \n",
       "4  ../CodeA/data/data/pos/10020_8.txt       1   \n",
       "\n",
       "                                             reviews  \\\n",
       "0  Homelessness (or Houselessness as George Carli...   \n",
       "1  You know, Robin Williams, God bless him, is co...   \n",
       "2  Like one of the previous commenters said, this...   \n",
       "3  When it comes to movies I can be pretty picky,...   \n",
       "4  The legendary Boris Karloff ended his illustri...   \n",
       "\n",
       "                                    tokenized_review  \n",
       "0  [homelessness, (, or, houselessness, as, georg...  \n",
       "1  [you, know, ,, robin, williams, ,, god, bless,...  \n",
       "2  [like, one, of, the, previous, commenters, sai...  \n",
       "3  [when, it, comes, to, movies, i, can, be, pret...  \n",
       "4  [the, legendary, boris, karloff, ended, his, i...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Tokenization - Data \n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "tokenized = []\n",
    "\n",
    "for i in df.index:\n",
    "    tokenized.append(word_tokenize(df['reviews'][i].lower()))\n",
    "    #tokenized.sort()\n",
    "    \n",
    "df.insert(3,'tokenized_review', tokenized,True) \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0f5bc88c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(',', 9), ('the', 9), ('is', 8), ('a', 7), ('.', 6), ('in', 6), ('andy', 6), ('of', 5), ('and', 5), ('he', 5), ('his', 4), ('virgin', 3), ('i', 3), ('to', 3), ('this', 3), ('40', 2), ('old', 2), ('it', 2), ('many', 2), ('present', 2), ('movie', 2), ('stitzer', 2), ('has', 2), ('by', 2), ('one', 2), ('specially', 2), ('are', 2), ('already', 2), ('<', 2), ('br', 2), ('/', 2), ('>', 2), ('with', 2), ('friends', 2), ('that', 2), ('...', 2), ('!', 2), ('woman', 2), (\"''the\", 1), ('year', 1), (\"''\", 1), (\"'made\", 1), ('me', 1), ('laugh', 1), ('lot', 1), ('do', 1), (\"n't\", 1), ('care', 1), ('if', 1), ('considered', 1)]\n"
     ]
    }
   ],
   "source": [
    "frequency_words = nltk.FreqDist(tokenized[0])\n",
    "print(frequency_words.most_common(50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6f3102cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='Samples', ylabel='Cumulative Counts'>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frequency_words.plot(30,cumulative=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f57aebef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('the', 7), ('<', 6), ('br', 6), ('/', 6), ('>', 6), ('.', 6), (',', 6), ('is', 5), ('for', 3), ('one', 2), ('in', 2), ('a', 2), ('time', 2), ('excellent', 2), ('and', 2), ('screen', 2), ('scene', 2), ('but', 2), (\"'before\", 1), ('devil', 1), ('knows', 1), ('you', 1), (\"'re\", 1), ('dead', 1), (\"'\", 1), ('of', 1), ('best', 1), ('movies', 1), ('i', 1), (\"'ve\", 1), ('seen', 1), ('long', 1), ('acting', 1), ('from', 1), ('ensemble', 1), ('cast', 1), ('incredible', 1), ('philip', 1), ('seymour', 1), ('hoffman', 1), ('putting', 1), ('an', 1), ('outstanding', 1), ('performance', 1), ('electrifying', 1), ('every', 1), ('he', 1), (\"'s\", 1), ('on', 1), ('ethan', 1)]\n"
     ]
    }
   ],
   "source": [
    "frequency_words = nltk.FreqDist(tokenized[1])\n",
    "print(frequency_words.most_common(50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3fe95006",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='Samples', ylabel='Cumulative Counts'>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frequency_words.plot(30,cumulative=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "879ab201",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preprocessing the reviews data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9d1544ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('zombi',)\n",
      "('3',)\n",
      "('has',)\n",
      "('an',)\n",
      "('interesting',)\n",
      "('history',)\n",
      "('in',)\n",
      "('it',)\n",
      "(\"'s\",)\n",
      "('making',)\n",
      "('.',)\n",
      "('firstly',)\n",
      "(',',)\n",
      "('it',)\n",
      "('is',)\n",
      "('a',)\n",
      "('sequel',)\n",
      "('to',)\n",
      "('fulci',)\n",
      "(\"'s\",)\n",
      "('hit',)\n",
      "('zombi',)\n",
      "('2',)\n",
      "(',',)\n",
      "('with',)\n",
      "('zombi',)\n",
      "('2',)\n",
      "('itself',)\n",
      "('being',)\n",
      "('of',)\n",
      "('course',)\n",
      "('a',)\n",
      "('marketing',)\n",
      "('ploy',)\n",
      "('to',)\n",
      "('trick',)\n",
      "('people',)\n",
      "('into',)\n",
      "('thinking',)\n",
      "('it',)\n",
      "('was',)\n",
      "('a',)\n",
      "('sequel',)\n",
      "('to',)\n",
      "('george',)\n",
      "('a.',)\n",
      "('romero',)\n",
      "(\"'s\",)\n",
      "('dawn',)\n",
      "('of',)\n",
      "('the',)\n",
      "('dead',)\n",
      "('aka',)\n",
      "('zombi',)\n",
      "('.',)\n",
      "('confusing',)\n",
      "('enough',)\n",
      "('?',)\n",
      "('basically',)\n",
      "(',',)\n",
      "('none',)\n",
      "('of',)\n",
      "('the',)\n",
      "('films',)\n",
      "('have',)\n",
      "('anything',)\n",
      "('to',)\n",
      "('do',)\n",
      "('with',)\n",
      "('one',)\n",
      "('another',)\n",
      "(',',)\n",
      "('but',)\n",
      "('who',)\n",
      "('cares',)\n",
      "('when',)\n",
      "('they',)\n",
      "('make',)\n",
      "('money',)\n",
      "('.',)\n",
      "('i',)\n",
      "('guess',)\n",
      "('fulci',)\n",
      "('himself',)\n",
      "('starting',)\n",
      "('to',)\n",
      "('not',)\n",
      "('care',)\n",
      "('about',)\n",
      "('the',)\n",
      "('production',)\n",
      "('about',)\n",
      "('half',)\n",
      "('way',)\n",
      "('through',)\n",
      "('zombi',)\n",
      "('3',)\n",
      "('when',)\n",
      "('he',)\n",
      "('decided',)\n",
      "('to',)\n",
      "('walk',)\n",
      "('out',)\n",
      "('.',)\n",
      "('bruno',)\n",
      "('mattei',)\n",
      "('was',)\n",
      "('brought',)\n",
      "('on',)\n",
      "('board',)\n",
      "('to',)\n",
      "('help',)\n",
      "('pad',)\n",
      "('the',)\n",
      "('film',)\n",
      "('with',)\n",
      "('additional',)\n",
      "('scenes',)\n",
      "('to',)\n",
      "('lengthen',)\n",
      "('the',)\n",
      "('running',)\n",
      "('time.',)\n",
      "('<',)\n",
      "('br',)\n",
      "('/',)\n",
      "('>',)\n",
      "('<',)\n",
      "('br',)\n",
      "('/',)\n",
      "('>',)\n",
      "('zombi',)\n",
      "('3',)\n",
      "(\"'s\",)\n",
      "('plot',)\n",
      "('is',)\n",
      "('your',)\n",
      "('typical',)\n",
      "('zombie',)\n",
      "('fare',)\n",
      "('.',)\n",
      "('scientists',)\n",
      "('develop',)\n",
      "('a',)\n",
      "('serum',)\n",
      "('on',)\n",
      "('an',)\n",
      "('island',)\n",
      "('in',)\n",
      "('the',)\n",
      "('philippines',)\n",
      "(',',)\n",
      "('terrorists',)\n",
      "('steal',)\n",
      "('it',)\n",
      "('unleashing',)\n",
      "('a',)\n",
      "('plague',)\n",
      "(',',)\n",
      "('and',)\n",
      "('zombie',)\n",
      "('run',)\n",
      "('amok',)\n",
      "('.',)\n",
      "('the',)\n",
      "('scientists',)\n",
      "('want',)\n",
      "('to',)\n",
      "('create',)\n",
      "('an',)\n",
      "('antidote',)\n",
      "(',',)\n",
      "('while',)\n",
      "('the',)\n",
      "('military',)\n",
      "('is',)\n",
      "('set',)\n",
      "('on',)\n",
      "('mowing',)\n",
      "('down',)\n",
      "('everyone',)\n",
      "('without',)\n",
      "('prejudice',)\n",
      "('.',)\n",
      "('there',)\n",
      "('are',)\n",
      "('also',)\n",
      "('brief',)\n",
      "('inserts',)\n",
      "('of',)\n",
      "('a',)\n",
      "('radio',)\n",
      "('dj',)\n",
      "('preaching',)\n",
      "('about',)\n",
      "('how',)\n",
      "('we',)\n",
      "('treat',)\n",
      "('the',)\n",
      "('planet',)\n",
      "('.',)\n",
      "('<',)\n",
      "('br',)\n",
      "('/',)\n",
      "('>',)\n",
      "('<',)\n",
      "('br',)\n",
      "('/',)\n",
      "('>',)\n",
      "('overall',)\n",
      "(',',)\n",
      "('i',)\n",
      "('actually',)\n",
      "('liked',)\n",
      "('this',)\n",
      "('film',)\n",
      "('.',)\n",
      "('i',)\n",
      "('heard',)\n",
      "('horrible',)\n",
      "('things',)\n",
      "(',',)\n",
      "('but',)\n",
      "('i',)\n",
      "('find',)\n",
      "('the',)\n",
      "('goofy',)\n",
      "('dialogue',)\n",
      "('quite',)\n",
      "('enjoyable',)\n",
      "('.',)\n",
      "('the',)\n",
      "('film',)\n",
      "('seems',)\n",
      "('to',)\n",
      "('be',)\n",
      "('an',)\n",
      "('attempt',)\n",
      "('at',)\n",
      "('raising',)\n",
      "('awareness',)\n",
      "('about',)\n",
      "('pollution',)\n",
      "(',',)\n",
      "('corrupted',)\n",
      "('military',)\n",
      "(',',)\n",
      "('man',)\n",
      "('playing',)\n",
      "('god',)\n",
      "(',',)\n",
      "('etc',)\n",
      "('.',)\n",
      "('i',)\n",
      "('get',)\n",
      "('the',)\n",
      "('feeling',)\n",
      "('this',)\n",
      "('was',)\n",
      "('at',)\n",
      "('one',)\n",
      "('point',)\n",
      "('a',)\n",
      "('serious',)\n",
      "('film',)\n",
      "(',',)\n",
      "('but',)\n",
      "('it',)\n",
      "('veered',)\n",
      "('off',)\n",
      "('in',)\n",
      "('a',)\n",
      "('weird',)\n",
      "('direction',)\n",
      "(',',)\n",
      "('presumably',)\n",
      "('when',)\n",
      "('mattei',)\n",
      "('came',)\n",
      "('on',)\n",
      "('board.',)\n",
      "('<',)\n",
      "('br',)\n",
      "('/',)\n",
      "('>',)\n",
      "('<',)\n",
      "('br',)\n",
      "('/',)\n",
      "('>',)\n",
      "('besides',)\n",
      "('ripping',)\n",
      "('off',)\n",
      "('other',)\n",
      "('zombie',)\n",
      "('flicks',)\n",
      "(',',)\n",
      "('this',)\n",
      "('was',)\n",
      "('very',)\n",
      "('reminiscent',)\n",
      "('of',)\n",
      "('romero',)\n",
      "(\"'s\",)\n",
      "('the',)\n",
      "('crazies',)\n",
      "('.',)\n",
      "('you',)\n",
      "('hear',)\n",
      "('the',)\n",
      "('radio',)\n",
      "('dj',)\n",
      "('breaking',)\n",
      "('the',)\n",
      "('good',)\n",
      "('news',)\n",
      "('with',)\n",
      "(',',)\n",
      "('``',)\n",
      "('when',)\n",
      "('you',)\n",
      "('see',)\n",
      "('the',)\n",
      "('men',)\n",
      "('in',)\n",
      "('white',)\n",
      "('suits',)\n",
      "('&',)\n",
      "('gas',)\n",
      "('masks',)\n",
      "(',',)\n",
      "('run',)\n",
      "('to',)\n",
      "('them',)\n",
      "('for',)\n",
      "('help',)\n",
      "('.',)\n",
      "(\"''\",)\n",
      "('this',)\n",
      "('is',)\n",
      "('of',)\n",
      "('course',)\n",
      "('played',)\n",
      "('to',)\n",
      "('the',)\n",
      "('images',)\n",
      "('of',)\n",
      "('the',)\n",
      "('men',)\n",
      "('in',)\n",
      "('white',)\n",
      "('gunning',)\n",
      "('down',)\n",
      "('zombies',)\n",
      "('.',)\n",
      "('later',)\n",
      "(',',)\n",
      "('they',)\n",
      "('straight',)\n",
      "('up',)\n",
      "('steal',)\n",
      "('a',)\n",
      "('scene',)\n",
      "('from',)\n",
      "('crazies',)\n",
      "('in',)\n",
      "('which',)\n",
      "('one',)\n",
      "('of',)\n",
      "('the',)\n",
      "('regular',)\n",
      "(',',)\n",
      "('uncontaminated',)\n",
      "('people',)\n",
      "('is',)\n",
      "('killed',)\n",
      "('by',)\n",
      "('mistake.',)\n",
      "('<',)\n",
      "('br',)\n",
      "('/',)\n",
      "('>',)\n",
      "('<',)\n",
      "('br',)\n",
      "('/',)\n",
      "('>',)\n",
      "('the',)\n",
      "('gore',)\n",
      "('factor',)\n",
      "('is',)\n",
      "('pretty',)\n",
      "('good',)\n",
      "('in',)\n",
      "('this',)\n",
      "('one',)\n",
      "('with',)\n",
      "('zombie',)\n",
      "('hordes',)\n",
      "('around',)\n",
      "('every',)\n",
      "('corner',)\n",
      "('.',)\n",
      "('how',)\n",
      "('is',)\n",
      "('it',)\n",
      "('cool',)\n",
      "('?',)\n",
      "('let',)\n",
      "('me',)\n",
      "('count',)\n",
      "('the',)\n",
      "('ways',)\n",
      "('1.',)\n",
      "('zombie',)\n",
      "('birth',)\n",
      "('2.',)\n",
      "('flying',)\n",
      "('zombie',)\n",
      "('head',)\n",
      "('3.',)\n",
      "('zombie',)\n",
      "('birds',)\n",
      "('.',)\n",
      "('4.',)\n",
      "('zombie',)\n",
      "('with',)\n",
      "('no',)\n",
      "('legs',)\n",
      "('swimming',)\n",
      "('in',)\n",
      "('a',)\n",
      "('pool',)\n",
      "('.',)\n",
      "('my',)\n",
      "('favorite',)\n",
      "('zombie',)\n",
      "('was',)\n",
      "('the',)\n",
      "('machete-wielding',)\n",
      "('maniac',)\n",
      "('at',)\n",
      "('the',)\n",
      "('gas',)\n",
      "('station',)\n",
      "('.',)\n",
      "('he',)\n",
      "('was',)\n",
      "('bad',)\n",
      "('ass',)\n",
      "('and',)\n",
      "('nearly',)\n",
      "('tore',)\n",
      "('down',)\n",
      "('the',)\n",
      "('entire',)\n",
      "('building',)\n",
      "('trying',)\n",
      "('to',)\n",
      "('kill',)\n",
      "('a',)\n",
      "('girl.',)\n",
      "('<',)\n",
      "('br',)\n",
      "('/',)\n",
      "('>',)\n",
      "('<',)\n",
      "('br',)\n",
      "('/',)\n",
      "('>',)\n",
      "('favorite',)\n",
      "('quote',)\n",
      "('\\x96',)\n",
      "('when',)\n",
      "('a',)\n",
      "('sergeant',)\n",
      "('insists',)\n",
      "('on',)\n",
      "('cremating',)\n",
      "('a',)\n",
      "('zombie',)\n",
      "(',',)\n",
      "('the',)\n",
      "('scientists',)\n",
      "('asks',)\n",
      "(',',)\n",
      "('``',)\n",
      "('do',)\n",
      "(\"n't\",)\n",
      "('you',)\n",
      "('think',)\n",
      "('that',)\n",
      "('once',)\n",
      "('the',)\n",
      "('ash',)\n",
      "('is',)\n",
      "('in',)\n",
      "('the',)\n",
      "('air',)\n",
      "(',',)\n",
      "('it',)\n",
      "('will',)\n",
      "('fall',)\n",
      "('to',)\n",
      "('the',)\n",
      "('ground',)\n",
      "(',',)\n",
      "('and',)\n",
      "('contaminate',)\n",
      "('everything',)\n",
      "('?',)\n",
      "(\"''\",)\n",
      "('to',)\n",
      "('which',)\n",
      "('the',)\n",
      "('sargeant',)\n",
      "('boldly',)\n",
      "('replies',)\n",
      "(',',)\n",
      "('``',)\n",
      "('now',)\n",
      "('you',)\n",
      "(\"'re\",)\n",
      "('talking',)\n",
      "('science',)\n",
      "('fiction',)\n",
      "('.',)\n",
      "(\"''\",)\n",
      "('he',)\n",
      "('also',)\n",
      "('continues',)\n",
      "('to',)\n",
      "('mention',)\n",
      "('the',)\n",
      "('``',)\n",
      "('science',)\n",
      "('fiction',)\n",
      "(\"''\",)\n",
      "('told',)\n",
      "('by',)\n",
      "('the',)\n",
      "('scientists',)\n",
      "('even',)\n",
      "('at',)\n",
      "('the',)\n",
      "('end',)\n",
      "('when',)\n",
      "('everyone',)\n",
      "('dies.',)\n",
      "('<',)\n",
      "('br',)\n",
      "('/',)\n",
      "('>',)\n",
      "('<',)\n",
      "('br',)\n",
      "('/',)\n",
      "('>',)\n",
      "('extras',)\n",
      "(':',)\n",
      "('gallery',)\n",
      "(',',)\n",
      "('trailers',)\n",
      "(',',)\n",
      "('and',)\n",
      "('interviews',)\n",
      "(',',)\n",
      "('most',)\n",
      "('notably',)\n",
      "('the',)\n",
      "('one',)\n",
      "('with',)\n",
      "('mattei',)\n",
      "('where',)\n",
      "('he',)\n",
      "('insists',)\n",
      "('he',)\n",
      "('directed',)\n",
      "('40',)\n",
      "('%',)\n",
      "('of',)\n",
      "('the',)\n",
      "('scenes',)\n",
      "(',',)\n",
      "('yet',)\n",
      "('can',)\n",
      "('not',)\n",
      "('recall',)\n",
      "('which',)\n",
      "('ones',)\n",
      "('or',)\n",
      "('any',)\n",
      "('other',)\n",
      "('significant',)\n",
      "('details.',)\n",
      "('<',)\n",
      "('br',)\n",
      "('/',)\n",
      "('>',)\n",
      "('<',)\n",
      "('br',)\n",
      "('/',)\n",
      "('>',)\n",
      "('bottom',)\n",
      "('line',)\n",
      "(':',)\n",
      "('a',)\n",
      "('must',)\n",
      "('see',)\n",
      "('for',)\n",
      "('zombie',)\n",
      "('and',)\n",
      "('fulci',)\n",
      "('fans.',)\n",
      "('<',)\n",
      "('br',)\n",
      "('/',)\n",
      "('>',)\n",
      "('<',)\n",
      "('br',)\n",
      "('/',)\n",
      "('>',)\n",
      "('rating',)\n",
      "(':',)\n",
      "('7/10',)\n",
      "('<',)\n",
      "('br',)\n",
      "('/',)\n",
      "('>',)\n",
      "('<',)\n",
      "('br',)\n",
      "('/',)\n",
      "('>',)\n",
      "('molly',)\n",
      "('celaschi',)\n",
      "('www.horroryearbook.com',)\n",
      "('myspace.com/horroryearbook',)\n"
     ]
    }
   ],
   "source": [
    "#Unigram\n",
    "for words in tokenized:\n",
    "    unigrams = ngrams(words, 1)\n",
    "    \n",
    "for unigram in unigrams:\n",
    "    print(unigram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d27f1828",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('zombi', '3')\n",
      "('3', 'has')\n",
      "('has', 'an')\n",
      "('an', 'interesting')\n",
      "('interesting', 'history')\n",
      "('history', 'in')\n",
      "('in', 'it')\n",
      "('it', \"'s\")\n",
      "(\"'s\", 'making')\n",
      "('making', '.')\n",
      "('.', 'firstly')\n",
      "('firstly', ',')\n",
      "(',', 'it')\n",
      "('it', 'is')\n",
      "('is', 'a')\n",
      "('a', 'sequel')\n",
      "('sequel', 'to')\n",
      "('to', 'fulci')\n",
      "('fulci', \"'s\")\n",
      "(\"'s\", 'hit')\n",
      "('hit', 'zombi')\n",
      "('zombi', '2')\n",
      "('2', ',')\n",
      "(',', 'with')\n",
      "('with', 'zombi')\n",
      "('zombi', '2')\n",
      "('2', 'itself')\n",
      "('itself', 'being')\n",
      "('being', 'of')\n",
      "('of', 'course')\n",
      "('course', 'a')\n",
      "('a', 'marketing')\n",
      "('marketing', 'ploy')\n",
      "('ploy', 'to')\n",
      "('to', 'trick')\n",
      "('trick', 'people')\n",
      "('people', 'into')\n",
      "('into', 'thinking')\n",
      "('thinking', 'it')\n",
      "('it', 'was')\n",
      "('was', 'a')\n",
      "('a', 'sequel')\n",
      "('sequel', 'to')\n",
      "('to', 'george')\n",
      "('george', 'a.')\n",
      "('a.', 'romero')\n",
      "('romero', \"'s\")\n",
      "(\"'s\", 'dawn')\n",
      "('dawn', 'of')\n",
      "('of', 'the')\n",
      "('the', 'dead')\n",
      "('dead', 'aka')\n",
      "('aka', 'zombi')\n",
      "('zombi', '.')\n",
      "('.', 'confusing')\n",
      "('confusing', 'enough')\n",
      "('enough', '?')\n",
      "('?', 'basically')\n",
      "('basically', ',')\n",
      "(',', 'none')\n",
      "('none', 'of')\n",
      "('of', 'the')\n",
      "('the', 'films')\n",
      "('films', 'have')\n",
      "('have', 'anything')\n",
      "('anything', 'to')\n",
      "('to', 'do')\n",
      "('do', 'with')\n",
      "('with', 'one')\n",
      "('one', 'another')\n",
      "('another', ',')\n",
      "(',', 'but')\n",
      "('but', 'who')\n",
      "('who', 'cares')\n",
      "('cares', 'when')\n",
      "('when', 'they')\n",
      "('they', 'make')\n",
      "('make', 'money')\n",
      "('money', '.')\n",
      "('.', 'i')\n",
      "('i', 'guess')\n",
      "('guess', 'fulci')\n",
      "('fulci', 'himself')\n",
      "('himself', 'starting')\n",
      "('starting', 'to')\n",
      "('to', 'not')\n",
      "('not', 'care')\n",
      "('care', 'about')\n",
      "('about', 'the')\n",
      "('the', 'production')\n",
      "('production', 'about')\n",
      "('about', 'half')\n",
      "('half', 'way')\n",
      "('way', 'through')\n",
      "('through', 'zombi')\n",
      "('zombi', '3')\n",
      "('3', 'when')\n",
      "('when', 'he')\n",
      "('he', 'decided')\n",
      "('decided', 'to')\n",
      "('to', 'walk')\n",
      "('walk', 'out')\n",
      "('out', '.')\n",
      "('.', 'bruno')\n",
      "('bruno', 'mattei')\n",
      "('mattei', 'was')\n",
      "('was', 'brought')\n",
      "('brought', 'on')\n",
      "('on', 'board')\n",
      "('board', 'to')\n",
      "('to', 'help')\n",
      "('help', 'pad')\n",
      "('pad', 'the')\n",
      "('the', 'film')\n",
      "('film', 'with')\n",
      "('with', 'additional')\n",
      "('additional', 'scenes')\n",
      "('scenes', 'to')\n",
      "('to', 'lengthen')\n",
      "('lengthen', 'the')\n",
      "('the', 'running')\n",
      "('running', 'time.')\n",
      "('time.', '<')\n",
      "('<', 'br')\n",
      "('br', '/')\n",
      "('/', '>')\n",
      "('>', '<')\n",
      "('<', 'br')\n",
      "('br', '/')\n",
      "('/', '>')\n",
      "('>', 'zombi')\n",
      "('zombi', '3')\n",
      "('3', \"'s\")\n",
      "(\"'s\", 'plot')\n",
      "('plot', 'is')\n",
      "('is', 'your')\n",
      "('your', 'typical')\n",
      "('typical', 'zombie')\n",
      "('zombie', 'fare')\n",
      "('fare', '.')\n",
      "('.', 'scientists')\n",
      "('scientists', 'develop')\n",
      "('develop', 'a')\n",
      "('a', 'serum')\n",
      "('serum', 'on')\n",
      "('on', 'an')\n",
      "('an', 'island')\n",
      "('island', 'in')\n",
      "('in', 'the')\n",
      "('the', 'philippines')\n",
      "('philippines', ',')\n",
      "(',', 'terrorists')\n",
      "('terrorists', 'steal')\n",
      "('steal', 'it')\n",
      "('it', 'unleashing')\n",
      "('unleashing', 'a')\n",
      "('a', 'plague')\n",
      "('plague', ',')\n",
      "(',', 'and')\n",
      "('and', 'zombie')\n",
      "('zombie', 'run')\n",
      "('run', 'amok')\n",
      "('amok', '.')\n",
      "('.', 'the')\n",
      "('the', 'scientists')\n",
      "('scientists', 'want')\n",
      "('want', 'to')\n",
      "('to', 'create')\n",
      "('create', 'an')\n",
      "('an', 'antidote')\n",
      "('antidote', ',')\n",
      "(',', 'while')\n",
      "('while', 'the')\n",
      "('the', 'military')\n",
      "('military', 'is')\n",
      "('is', 'set')\n",
      "('set', 'on')\n",
      "('on', 'mowing')\n",
      "('mowing', 'down')\n",
      "('down', 'everyone')\n",
      "('everyone', 'without')\n",
      "('without', 'prejudice')\n",
      "('prejudice', '.')\n",
      "('.', 'there')\n",
      "('there', 'are')\n",
      "('are', 'also')\n",
      "('also', 'brief')\n",
      "('brief', 'inserts')\n",
      "('inserts', 'of')\n",
      "('of', 'a')\n",
      "('a', 'radio')\n",
      "('radio', 'dj')\n",
      "('dj', 'preaching')\n",
      "('preaching', 'about')\n",
      "('about', 'how')\n",
      "('how', 'we')\n",
      "('we', 'treat')\n",
      "('treat', 'the')\n",
      "('the', 'planet')\n",
      "('planet', '.')\n",
      "('.', '<')\n",
      "('<', 'br')\n",
      "('br', '/')\n",
      "('/', '>')\n",
      "('>', '<')\n",
      "('<', 'br')\n",
      "('br', '/')\n",
      "('/', '>')\n",
      "('>', 'overall')\n",
      "('overall', ',')\n",
      "(',', 'i')\n",
      "('i', 'actually')\n",
      "('actually', 'liked')\n",
      "('liked', 'this')\n",
      "('this', 'film')\n",
      "('film', '.')\n",
      "('.', 'i')\n",
      "('i', 'heard')\n",
      "('heard', 'horrible')\n",
      "('horrible', 'things')\n",
      "('things', ',')\n",
      "(',', 'but')\n",
      "('but', 'i')\n",
      "('i', 'find')\n",
      "('find', 'the')\n",
      "('the', 'goofy')\n",
      "('goofy', 'dialogue')\n",
      "('dialogue', 'quite')\n",
      "('quite', 'enjoyable')\n",
      "('enjoyable', '.')\n",
      "('.', 'the')\n",
      "('the', 'film')\n",
      "('film', 'seems')\n",
      "('seems', 'to')\n",
      "('to', 'be')\n",
      "('be', 'an')\n",
      "('an', 'attempt')\n",
      "('attempt', 'at')\n",
      "('at', 'raising')\n",
      "('raising', 'awareness')\n",
      "('awareness', 'about')\n",
      "('about', 'pollution')\n",
      "('pollution', ',')\n",
      "(',', 'corrupted')\n",
      "('corrupted', 'military')\n",
      "('military', ',')\n",
      "(',', 'man')\n",
      "('man', 'playing')\n",
      "('playing', 'god')\n",
      "('god', ',')\n",
      "(',', 'etc')\n",
      "('etc', '.')\n",
      "('.', 'i')\n",
      "('i', 'get')\n",
      "('get', 'the')\n",
      "('the', 'feeling')\n",
      "('feeling', 'this')\n",
      "('this', 'was')\n",
      "('was', 'at')\n",
      "('at', 'one')\n",
      "('one', 'point')\n",
      "('point', 'a')\n",
      "('a', 'serious')\n",
      "('serious', 'film')\n",
      "('film', ',')\n",
      "(',', 'but')\n",
      "('but', 'it')\n",
      "('it', 'veered')\n",
      "('veered', 'off')\n",
      "('off', 'in')\n",
      "('in', 'a')\n",
      "('a', 'weird')\n",
      "('weird', 'direction')\n",
      "('direction', ',')\n",
      "(',', 'presumably')\n",
      "('presumably', 'when')\n",
      "('when', 'mattei')\n",
      "('mattei', 'came')\n",
      "('came', 'on')\n",
      "('on', 'board.')\n",
      "('board.', '<')\n",
      "('<', 'br')\n",
      "('br', '/')\n",
      "('/', '>')\n",
      "('>', '<')\n",
      "('<', 'br')\n",
      "('br', '/')\n",
      "('/', '>')\n",
      "('>', 'besides')\n",
      "('besides', 'ripping')\n",
      "('ripping', 'off')\n",
      "('off', 'other')\n",
      "('other', 'zombie')\n",
      "('zombie', 'flicks')\n",
      "('flicks', ',')\n",
      "(',', 'this')\n",
      "('this', 'was')\n",
      "('was', 'very')\n",
      "('very', 'reminiscent')\n",
      "('reminiscent', 'of')\n",
      "('of', 'romero')\n",
      "('romero', \"'s\")\n",
      "(\"'s\", 'the')\n",
      "('the', 'crazies')\n",
      "('crazies', '.')\n",
      "('.', 'you')\n",
      "('you', 'hear')\n",
      "('hear', 'the')\n",
      "('the', 'radio')\n",
      "('radio', 'dj')\n",
      "('dj', 'breaking')\n",
      "('breaking', 'the')\n",
      "('the', 'good')\n",
      "('good', 'news')\n",
      "('news', 'with')\n",
      "('with', ',')\n",
      "(',', '``')\n",
      "('``', 'when')\n",
      "('when', 'you')\n",
      "('you', 'see')\n",
      "('see', 'the')\n",
      "('the', 'men')\n",
      "('men', 'in')\n",
      "('in', 'white')\n",
      "('white', 'suits')\n",
      "('suits', '&')\n",
      "('&', 'gas')\n",
      "('gas', 'masks')\n",
      "('masks', ',')\n",
      "(',', 'run')\n",
      "('run', 'to')\n",
      "('to', 'them')\n",
      "('them', 'for')\n",
      "('for', 'help')\n",
      "('help', '.')\n",
      "('.', \"''\")\n",
      "(\"''\", 'this')\n",
      "('this', 'is')\n",
      "('is', 'of')\n",
      "('of', 'course')\n",
      "('course', 'played')\n",
      "('played', 'to')\n",
      "('to', 'the')\n",
      "('the', 'images')\n",
      "('images', 'of')\n",
      "('of', 'the')\n",
      "('the', 'men')\n",
      "('men', 'in')\n",
      "('in', 'white')\n",
      "('white', 'gunning')\n",
      "('gunning', 'down')\n",
      "('down', 'zombies')\n",
      "('zombies', '.')\n",
      "('.', 'later')\n",
      "('later', ',')\n",
      "(',', 'they')\n",
      "('they', 'straight')\n",
      "('straight', 'up')\n",
      "('up', 'steal')\n",
      "('steal', 'a')\n",
      "('a', 'scene')\n",
      "('scene', 'from')\n",
      "('from', 'crazies')\n",
      "('crazies', 'in')\n",
      "('in', 'which')\n",
      "('which', 'one')\n",
      "('one', 'of')\n",
      "('of', 'the')\n",
      "('the', 'regular')\n",
      "('regular', ',')\n",
      "(',', 'uncontaminated')\n",
      "('uncontaminated', 'people')\n",
      "('people', 'is')\n",
      "('is', 'killed')\n",
      "('killed', 'by')\n",
      "('by', 'mistake.')\n",
      "('mistake.', '<')\n",
      "('<', 'br')\n",
      "('br', '/')\n",
      "('/', '>')\n",
      "('>', '<')\n",
      "('<', 'br')\n",
      "('br', '/')\n",
      "('/', '>')\n",
      "('>', 'the')\n",
      "('the', 'gore')\n",
      "('gore', 'factor')\n",
      "('factor', 'is')\n",
      "('is', 'pretty')\n",
      "('pretty', 'good')\n",
      "('good', 'in')\n",
      "('in', 'this')\n",
      "('this', 'one')\n",
      "('one', 'with')\n",
      "('with', 'zombie')\n",
      "('zombie', 'hordes')\n",
      "('hordes', 'around')\n",
      "('around', 'every')\n",
      "('every', 'corner')\n",
      "('corner', '.')\n",
      "('.', 'how')\n",
      "('how', 'is')\n",
      "('is', 'it')\n",
      "('it', 'cool')\n",
      "('cool', '?')\n",
      "('?', 'let')\n",
      "('let', 'me')\n",
      "('me', 'count')\n",
      "('count', 'the')\n",
      "('the', 'ways')\n",
      "('ways', '1.')\n",
      "('1.', 'zombie')\n",
      "('zombie', 'birth')\n",
      "('birth', '2.')\n",
      "('2.', 'flying')\n",
      "('flying', 'zombie')\n",
      "('zombie', 'head')\n",
      "('head', '3.')\n",
      "('3.', 'zombie')\n",
      "('zombie', 'birds')\n",
      "('birds', '.')\n",
      "('.', '4.')\n",
      "('4.', 'zombie')\n",
      "('zombie', 'with')\n",
      "('with', 'no')\n",
      "('no', 'legs')\n",
      "('legs', 'swimming')\n",
      "('swimming', 'in')\n",
      "('in', 'a')\n",
      "('a', 'pool')\n",
      "('pool', '.')\n",
      "('.', 'my')\n",
      "('my', 'favorite')\n",
      "('favorite', 'zombie')\n",
      "('zombie', 'was')\n",
      "('was', 'the')\n",
      "('the', 'machete-wielding')\n",
      "('machete-wielding', 'maniac')\n",
      "('maniac', 'at')\n",
      "('at', 'the')\n",
      "('the', 'gas')\n",
      "('gas', 'station')\n",
      "('station', '.')\n",
      "('.', 'he')\n",
      "('he', 'was')\n",
      "('was', 'bad')\n",
      "('bad', 'ass')\n",
      "('ass', 'and')\n",
      "('and', 'nearly')\n",
      "('nearly', 'tore')\n",
      "('tore', 'down')\n",
      "('down', 'the')\n",
      "('the', 'entire')\n",
      "('entire', 'building')\n",
      "('building', 'trying')\n",
      "('trying', 'to')\n",
      "('to', 'kill')\n",
      "('kill', 'a')\n",
      "('a', 'girl.')\n",
      "('girl.', '<')\n",
      "('<', 'br')\n",
      "('br', '/')\n",
      "('/', '>')\n",
      "('>', '<')\n",
      "('<', 'br')\n",
      "('br', '/')\n",
      "('/', '>')\n",
      "('>', 'favorite')\n",
      "('favorite', 'quote')\n",
      "('quote', '\\x96')\n",
      "('\\x96', 'when')\n",
      "('when', 'a')\n",
      "('a', 'sergeant')\n",
      "('sergeant', 'insists')\n",
      "('insists', 'on')\n",
      "('on', 'cremating')\n",
      "('cremating', 'a')\n",
      "('a', 'zombie')\n",
      "('zombie', ',')\n",
      "(',', 'the')\n",
      "('the', 'scientists')\n",
      "('scientists', 'asks')\n",
      "('asks', ',')\n",
      "(',', '``')\n",
      "('``', 'do')\n",
      "('do', \"n't\")\n",
      "(\"n't\", 'you')\n",
      "('you', 'think')\n",
      "('think', 'that')\n",
      "('that', 'once')\n",
      "('once', 'the')\n",
      "('the', 'ash')\n",
      "('ash', 'is')\n",
      "('is', 'in')\n",
      "('in', 'the')\n",
      "('the', 'air')\n",
      "('air', ',')\n",
      "(',', 'it')\n",
      "('it', 'will')\n",
      "('will', 'fall')\n",
      "('fall', 'to')\n",
      "('to', 'the')\n",
      "('the', 'ground')\n",
      "('ground', ',')\n",
      "(',', 'and')\n",
      "('and', 'contaminate')\n",
      "('contaminate', 'everything')\n",
      "('everything', '?')\n",
      "('?', \"''\")\n",
      "(\"''\", 'to')\n",
      "('to', 'which')\n",
      "('which', 'the')\n",
      "('the', 'sargeant')\n",
      "('sargeant', 'boldly')\n",
      "('boldly', 'replies')\n",
      "('replies', ',')\n",
      "(',', '``')\n",
      "('``', 'now')\n",
      "('now', 'you')\n",
      "('you', \"'re\")\n",
      "(\"'re\", 'talking')\n",
      "('talking', 'science')\n",
      "('science', 'fiction')\n",
      "('fiction', '.')\n",
      "('.', \"''\")\n",
      "(\"''\", 'he')\n",
      "('he', 'also')\n",
      "('also', 'continues')\n",
      "('continues', 'to')\n",
      "('to', 'mention')\n",
      "('mention', 'the')\n",
      "('the', '``')\n",
      "('``', 'science')\n",
      "('science', 'fiction')\n",
      "('fiction', \"''\")\n",
      "(\"''\", 'told')\n",
      "('told', 'by')\n",
      "('by', 'the')\n",
      "('the', 'scientists')\n",
      "('scientists', 'even')\n",
      "('even', 'at')\n",
      "('at', 'the')\n",
      "('the', 'end')\n",
      "('end', 'when')\n",
      "('when', 'everyone')\n",
      "('everyone', 'dies.')\n",
      "('dies.', '<')\n",
      "('<', 'br')\n",
      "('br', '/')\n",
      "('/', '>')\n",
      "('>', '<')\n",
      "('<', 'br')\n",
      "('br', '/')\n",
      "('/', '>')\n",
      "('>', 'extras')\n",
      "('extras', ':')\n",
      "(':', 'gallery')\n",
      "('gallery', ',')\n",
      "(',', 'trailers')\n",
      "('trailers', ',')\n",
      "(',', 'and')\n",
      "('and', 'interviews')\n",
      "('interviews', ',')\n",
      "(',', 'most')\n",
      "('most', 'notably')\n",
      "('notably', 'the')\n",
      "('the', 'one')\n",
      "('one', 'with')\n",
      "('with', 'mattei')\n",
      "('mattei', 'where')\n",
      "('where', 'he')\n",
      "('he', 'insists')\n",
      "('insists', 'he')\n",
      "('he', 'directed')\n",
      "('directed', '40')\n",
      "('40', '%')\n",
      "('%', 'of')\n",
      "('of', 'the')\n",
      "('the', 'scenes')\n",
      "('scenes', ',')\n",
      "(',', 'yet')\n",
      "('yet', 'can')\n",
      "('can', 'not')\n",
      "('not', 'recall')\n",
      "('recall', 'which')\n",
      "('which', 'ones')\n",
      "('ones', 'or')\n",
      "('or', 'any')\n",
      "('any', 'other')\n",
      "('other', 'significant')\n",
      "('significant', 'details.')\n",
      "('details.', '<')\n",
      "('<', 'br')\n",
      "('br', '/')\n",
      "('/', '>')\n",
      "('>', '<')\n",
      "('<', 'br')\n",
      "('br', '/')\n",
      "('/', '>')\n",
      "('>', 'bottom')\n",
      "('bottom', 'line')\n",
      "('line', ':')\n",
      "(':', 'a')\n",
      "('a', 'must')\n",
      "('must', 'see')\n",
      "('see', 'for')\n",
      "('for', 'zombie')\n",
      "('zombie', 'and')\n",
      "('and', 'fulci')\n",
      "('fulci', 'fans.')\n",
      "('fans.', '<')\n",
      "('<', 'br')\n",
      "('br', '/')\n",
      "('/', '>')\n",
      "('>', '<')\n",
      "('<', 'br')\n",
      "('br', '/')\n",
      "('/', '>')\n",
      "('>', 'rating')\n",
      "('rating', ':')\n",
      "(':', '7/10')\n",
      "('7/10', '<')\n",
      "('<', 'br')\n",
      "('br', '/')\n",
      "('/', '>')\n",
      "('>', '<')\n",
      "('<', 'br')\n",
      "('br', '/')\n",
      "('/', '>')\n",
      "('>', 'molly')\n",
      "('molly', 'celaschi')\n",
      "('celaschi', 'www.horroryearbook.com')\n",
      "('www.horroryearbook.com', 'myspace.com/horroryearbook')\n"
     ]
    }
   ],
   "source": [
    "#Bigram\n",
    "for words in tokenized:\n",
    "    bigrams = ngrams(words, 2)\n",
    "    \n",
    "for bigram in bigrams:\n",
    "    print(bigram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fa89c613",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('zombi', '3', 'has')\n",
      "('3', 'has', 'an')\n",
      "('has', 'an', 'interesting')\n",
      "('an', 'interesting', 'history')\n",
      "('interesting', 'history', 'in')\n",
      "('history', 'in', 'it')\n",
      "('in', 'it', \"'s\")\n",
      "('it', \"'s\", 'making')\n",
      "(\"'s\", 'making', '.')\n",
      "('making', '.', 'firstly')\n",
      "('.', 'firstly', ',')\n",
      "('firstly', ',', 'it')\n",
      "(',', 'it', 'is')\n",
      "('it', 'is', 'a')\n",
      "('is', 'a', 'sequel')\n",
      "('a', 'sequel', 'to')\n",
      "('sequel', 'to', 'fulci')\n",
      "('to', 'fulci', \"'s\")\n",
      "('fulci', \"'s\", 'hit')\n",
      "(\"'s\", 'hit', 'zombi')\n",
      "('hit', 'zombi', '2')\n",
      "('zombi', '2', ',')\n",
      "('2', ',', 'with')\n",
      "(',', 'with', 'zombi')\n",
      "('with', 'zombi', '2')\n",
      "('zombi', '2', 'itself')\n",
      "('2', 'itself', 'being')\n",
      "('itself', 'being', 'of')\n",
      "('being', 'of', 'course')\n",
      "('of', 'course', 'a')\n",
      "('course', 'a', 'marketing')\n",
      "('a', 'marketing', 'ploy')\n",
      "('marketing', 'ploy', 'to')\n",
      "('ploy', 'to', 'trick')\n",
      "('to', 'trick', 'people')\n",
      "('trick', 'people', 'into')\n",
      "('people', 'into', 'thinking')\n",
      "('into', 'thinking', 'it')\n",
      "('thinking', 'it', 'was')\n",
      "('it', 'was', 'a')\n",
      "('was', 'a', 'sequel')\n",
      "('a', 'sequel', 'to')\n",
      "('sequel', 'to', 'george')\n",
      "('to', 'george', 'a.')\n",
      "('george', 'a.', 'romero')\n",
      "('a.', 'romero', \"'s\")\n",
      "('romero', \"'s\", 'dawn')\n",
      "(\"'s\", 'dawn', 'of')\n",
      "('dawn', 'of', 'the')\n",
      "('of', 'the', 'dead')\n",
      "('the', 'dead', 'aka')\n",
      "('dead', 'aka', 'zombi')\n",
      "('aka', 'zombi', '.')\n",
      "('zombi', '.', 'confusing')\n",
      "('.', 'confusing', 'enough')\n",
      "('confusing', 'enough', '?')\n",
      "('enough', '?', 'basically')\n",
      "('?', 'basically', ',')\n",
      "('basically', ',', 'none')\n",
      "(',', 'none', 'of')\n",
      "('none', 'of', 'the')\n",
      "('of', 'the', 'films')\n",
      "('the', 'films', 'have')\n",
      "('films', 'have', 'anything')\n",
      "('have', 'anything', 'to')\n",
      "('anything', 'to', 'do')\n",
      "('to', 'do', 'with')\n",
      "('do', 'with', 'one')\n",
      "('with', 'one', 'another')\n",
      "('one', 'another', ',')\n",
      "('another', ',', 'but')\n",
      "(',', 'but', 'who')\n",
      "('but', 'who', 'cares')\n",
      "('who', 'cares', 'when')\n",
      "('cares', 'when', 'they')\n",
      "('when', 'they', 'make')\n",
      "('they', 'make', 'money')\n",
      "('make', 'money', '.')\n",
      "('money', '.', 'i')\n",
      "('.', 'i', 'guess')\n",
      "('i', 'guess', 'fulci')\n",
      "('guess', 'fulci', 'himself')\n",
      "('fulci', 'himself', 'starting')\n",
      "('himself', 'starting', 'to')\n",
      "('starting', 'to', 'not')\n",
      "('to', 'not', 'care')\n",
      "('not', 'care', 'about')\n",
      "('care', 'about', 'the')\n",
      "('about', 'the', 'production')\n",
      "('the', 'production', 'about')\n",
      "('production', 'about', 'half')\n",
      "('about', 'half', 'way')\n",
      "('half', 'way', 'through')\n",
      "('way', 'through', 'zombi')\n",
      "('through', 'zombi', '3')\n",
      "('zombi', '3', 'when')\n",
      "('3', 'when', 'he')\n",
      "('when', 'he', 'decided')\n",
      "('he', 'decided', 'to')\n",
      "('decided', 'to', 'walk')\n",
      "('to', 'walk', 'out')\n",
      "('walk', 'out', '.')\n",
      "('out', '.', 'bruno')\n",
      "('.', 'bruno', 'mattei')\n",
      "('bruno', 'mattei', 'was')\n",
      "('mattei', 'was', 'brought')\n",
      "('was', 'brought', 'on')\n",
      "('brought', 'on', 'board')\n",
      "('on', 'board', 'to')\n",
      "('board', 'to', 'help')\n",
      "('to', 'help', 'pad')\n",
      "('help', 'pad', 'the')\n",
      "('pad', 'the', 'film')\n",
      "('the', 'film', 'with')\n",
      "('film', 'with', 'additional')\n",
      "('with', 'additional', 'scenes')\n",
      "('additional', 'scenes', 'to')\n",
      "('scenes', 'to', 'lengthen')\n",
      "('to', 'lengthen', 'the')\n",
      "('lengthen', 'the', 'running')\n",
      "('the', 'running', 'time.')\n",
      "('running', 'time.', '<')\n",
      "('time.', '<', 'br')\n",
      "('<', 'br', '/')\n",
      "('br', '/', '>')\n",
      "('/', '>', '<')\n",
      "('>', '<', 'br')\n",
      "('<', 'br', '/')\n",
      "('br', '/', '>')\n",
      "('/', '>', 'zombi')\n",
      "('>', 'zombi', '3')\n",
      "('zombi', '3', \"'s\")\n",
      "('3', \"'s\", 'plot')\n",
      "(\"'s\", 'plot', 'is')\n",
      "('plot', 'is', 'your')\n",
      "('is', 'your', 'typical')\n",
      "('your', 'typical', 'zombie')\n",
      "('typical', 'zombie', 'fare')\n",
      "('zombie', 'fare', '.')\n",
      "('fare', '.', 'scientists')\n",
      "('.', 'scientists', 'develop')\n",
      "('scientists', 'develop', 'a')\n",
      "('develop', 'a', 'serum')\n",
      "('a', 'serum', 'on')\n",
      "('serum', 'on', 'an')\n",
      "('on', 'an', 'island')\n",
      "('an', 'island', 'in')\n",
      "('island', 'in', 'the')\n",
      "('in', 'the', 'philippines')\n",
      "('the', 'philippines', ',')\n",
      "('philippines', ',', 'terrorists')\n",
      "(',', 'terrorists', 'steal')\n",
      "('terrorists', 'steal', 'it')\n",
      "('steal', 'it', 'unleashing')\n",
      "('it', 'unleashing', 'a')\n",
      "('unleashing', 'a', 'plague')\n",
      "('a', 'plague', ',')\n",
      "('plague', ',', 'and')\n",
      "(',', 'and', 'zombie')\n",
      "('and', 'zombie', 'run')\n",
      "('zombie', 'run', 'amok')\n",
      "('run', 'amok', '.')\n",
      "('amok', '.', 'the')\n",
      "('.', 'the', 'scientists')\n",
      "('the', 'scientists', 'want')\n",
      "('scientists', 'want', 'to')\n",
      "('want', 'to', 'create')\n",
      "('to', 'create', 'an')\n",
      "('create', 'an', 'antidote')\n",
      "('an', 'antidote', ',')\n",
      "('antidote', ',', 'while')\n",
      "(',', 'while', 'the')\n",
      "('while', 'the', 'military')\n",
      "('the', 'military', 'is')\n",
      "('military', 'is', 'set')\n",
      "('is', 'set', 'on')\n",
      "('set', 'on', 'mowing')\n",
      "('on', 'mowing', 'down')\n",
      "('mowing', 'down', 'everyone')\n",
      "('down', 'everyone', 'without')\n",
      "('everyone', 'without', 'prejudice')\n",
      "('without', 'prejudice', '.')\n",
      "('prejudice', '.', 'there')\n",
      "('.', 'there', 'are')\n",
      "('there', 'are', 'also')\n",
      "('are', 'also', 'brief')\n",
      "('also', 'brief', 'inserts')\n",
      "('brief', 'inserts', 'of')\n",
      "('inserts', 'of', 'a')\n",
      "('of', 'a', 'radio')\n",
      "('a', 'radio', 'dj')\n",
      "('radio', 'dj', 'preaching')\n",
      "('dj', 'preaching', 'about')\n",
      "('preaching', 'about', 'how')\n",
      "('about', 'how', 'we')\n",
      "('how', 'we', 'treat')\n",
      "('we', 'treat', 'the')\n",
      "('treat', 'the', 'planet')\n",
      "('the', 'planet', '.')\n",
      "('planet', '.', '<')\n",
      "('.', '<', 'br')\n",
      "('<', 'br', '/')\n",
      "('br', '/', '>')\n",
      "('/', '>', '<')\n",
      "('>', '<', 'br')\n",
      "('<', 'br', '/')\n",
      "('br', '/', '>')\n",
      "('/', '>', 'overall')\n",
      "('>', 'overall', ',')\n",
      "('overall', ',', 'i')\n",
      "(',', 'i', 'actually')\n",
      "('i', 'actually', 'liked')\n",
      "('actually', 'liked', 'this')\n",
      "('liked', 'this', 'film')\n",
      "('this', 'film', '.')\n",
      "('film', '.', 'i')\n",
      "('.', 'i', 'heard')\n",
      "('i', 'heard', 'horrible')\n",
      "('heard', 'horrible', 'things')\n",
      "('horrible', 'things', ',')\n",
      "('things', ',', 'but')\n",
      "(',', 'but', 'i')\n",
      "('but', 'i', 'find')\n",
      "('i', 'find', 'the')\n",
      "('find', 'the', 'goofy')\n",
      "('the', 'goofy', 'dialogue')\n",
      "('goofy', 'dialogue', 'quite')\n",
      "('dialogue', 'quite', 'enjoyable')\n",
      "('quite', 'enjoyable', '.')\n",
      "('enjoyable', '.', 'the')\n",
      "('.', 'the', 'film')\n",
      "('the', 'film', 'seems')\n",
      "('film', 'seems', 'to')\n",
      "('seems', 'to', 'be')\n",
      "('to', 'be', 'an')\n",
      "('be', 'an', 'attempt')\n",
      "('an', 'attempt', 'at')\n",
      "('attempt', 'at', 'raising')\n",
      "('at', 'raising', 'awareness')\n",
      "('raising', 'awareness', 'about')\n",
      "('awareness', 'about', 'pollution')\n",
      "('about', 'pollution', ',')\n",
      "('pollution', ',', 'corrupted')\n",
      "(',', 'corrupted', 'military')\n",
      "('corrupted', 'military', ',')\n",
      "('military', ',', 'man')\n",
      "(',', 'man', 'playing')\n",
      "('man', 'playing', 'god')\n",
      "('playing', 'god', ',')\n",
      "('god', ',', 'etc')\n",
      "(',', 'etc', '.')\n",
      "('etc', '.', 'i')\n",
      "('.', 'i', 'get')\n",
      "('i', 'get', 'the')\n",
      "('get', 'the', 'feeling')\n",
      "('the', 'feeling', 'this')\n",
      "('feeling', 'this', 'was')\n",
      "('this', 'was', 'at')\n",
      "('was', 'at', 'one')\n",
      "('at', 'one', 'point')\n",
      "('one', 'point', 'a')\n",
      "('point', 'a', 'serious')\n",
      "('a', 'serious', 'film')\n",
      "('serious', 'film', ',')\n",
      "('film', ',', 'but')\n",
      "(',', 'but', 'it')\n",
      "('but', 'it', 'veered')\n",
      "('it', 'veered', 'off')\n",
      "('veered', 'off', 'in')\n",
      "('off', 'in', 'a')\n",
      "('in', 'a', 'weird')\n",
      "('a', 'weird', 'direction')\n",
      "('weird', 'direction', ',')\n",
      "('direction', ',', 'presumably')\n",
      "(',', 'presumably', 'when')\n",
      "('presumably', 'when', 'mattei')\n",
      "('when', 'mattei', 'came')\n",
      "('mattei', 'came', 'on')\n",
      "('came', 'on', 'board.')\n",
      "('on', 'board.', '<')\n",
      "('board.', '<', 'br')\n",
      "('<', 'br', '/')\n",
      "('br', '/', '>')\n",
      "('/', '>', '<')\n",
      "('>', '<', 'br')\n",
      "('<', 'br', '/')\n",
      "('br', '/', '>')\n",
      "('/', '>', 'besides')\n",
      "('>', 'besides', 'ripping')\n",
      "('besides', 'ripping', 'off')\n",
      "('ripping', 'off', 'other')\n",
      "('off', 'other', 'zombie')\n",
      "('other', 'zombie', 'flicks')\n",
      "('zombie', 'flicks', ',')\n",
      "('flicks', ',', 'this')\n",
      "(',', 'this', 'was')\n",
      "('this', 'was', 'very')\n",
      "('was', 'very', 'reminiscent')\n",
      "('very', 'reminiscent', 'of')\n",
      "('reminiscent', 'of', 'romero')\n",
      "('of', 'romero', \"'s\")\n",
      "('romero', \"'s\", 'the')\n",
      "(\"'s\", 'the', 'crazies')\n",
      "('the', 'crazies', '.')\n",
      "('crazies', '.', 'you')\n",
      "('.', 'you', 'hear')\n",
      "('you', 'hear', 'the')\n",
      "('hear', 'the', 'radio')\n",
      "('the', 'radio', 'dj')\n",
      "('radio', 'dj', 'breaking')\n",
      "('dj', 'breaking', 'the')\n",
      "('breaking', 'the', 'good')\n",
      "('the', 'good', 'news')\n",
      "('good', 'news', 'with')\n",
      "('news', 'with', ',')\n",
      "('with', ',', '``')\n",
      "(',', '``', 'when')\n",
      "('``', 'when', 'you')\n",
      "('when', 'you', 'see')\n",
      "('you', 'see', 'the')\n",
      "('see', 'the', 'men')\n",
      "('the', 'men', 'in')\n",
      "('men', 'in', 'white')\n",
      "('in', 'white', 'suits')\n",
      "('white', 'suits', '&')\n",
      "('suits', '&', 'gas')\n",
      "('&', 'gas', 'masks')\n",
      "('gas', 'masks', ',')\n",
      "('masks', ',', 'run')\n",
      "(',', 'run', 'to')\n",
      "('run', 'to', 'them')\n",
      "('to', 'them', 'for')\n",
      "('them', 'for', 'help')\n",
      "('for', 'help', '.')\n",
      "('help', '.', \"''\")\n",
      "('.', \"''\", 'this')\n",
      "(\"''\", 'this', 'is')\n",
      "('this', 'is', 'of')\n",
      "('is', 'of', 'course')\n",
      "('of', 'course', 'played')\n",
      "('course', 'played', 'to')\n",
      "('played', 'to', 'the')\n",
      "('to', 'the', 'images')\n",
      "('the', 'images', 'of')\n",
      "('images', 'of', 'the')\n",
      "('of', 'the', 'men')\n",
      "('the', 'men', 'in')\n",
      "('men', 'in', 'white')\n",
      "('in', 'white', 'gunning')\n",
      "('white', 'gunning', 'down')\n",
      "('gunning', 'down', 'zombies')\n",
      "('down', 'zombies', '.')\n",
      "('zombies', '.', 'later')\n",
      "('.', 'later', ',')\n",
      "('later', ',', 'they')\n",
      "(',', 'they', 'straight')\n",
      "('they', 'straight', 'up')\n",
      "('straight', 'up', 'steal')\n",
      "('up', 'steal', 'a')\n",
      "('steal', 'a', 'scene')\n",
      "('a', 'scene', 'from')\n",
      "('scene', 'from', 'crazies')\n",
      "('from', 'crazies', 'in')\n",
      "('crazies', 'in', 'which')\n",
      "('in', 'which', 'one')\n",
      "('which', 'one', 'of')\n",
      "('one', 'of', 'the')\n",
      "('of', 'the', 'regular')\n",
      "('the', 'regular', ',')\n",
      "('regular', ',', 'uncontaminated')\n",
      "(',', 'uncontaminated', 'people')\n",
      "('uncontaminated', 'people', 'is')\n",
      "('people', 'is', 'killed')\n",
      "('is', 'killed', 'by')\n",
      "('killed', 'by', 'mistake.')\n",
      "('by', 'mistake.', '<')\n",
      "('mistake.', '<', 'br')\n",
      "('<', 'br', '/')\n",
      "('br', '/', '>')\n",
      "('/', '>', '<')\n",
      "('>', '<', 'br')\n",
      "('<', 'br', '/')\n",
      "('br', '/', '>')\n",
      "('/', '>', 'the')\n",
      "('>', 'the', 'gore')\n",
      "('the', 'gore', 'factor')\n",
      "('gore', 'factor', 'is')\n",
      "('factor', 'is', 'pretty')\n",
      "('is', 'pretty', 'good')\n",
      "('pretty', 'good', 'in')\n",
      "('good', 'in', 'this')\n",
      "('in', 'this', 'one')\n",
      "('this', 'one', 'with')\n",
      "('one', 'with', 'zombie')\n",
      "('with', 'zombie', 'hordes')\n",
      "('zombie', 'hordes', 'around')\n",
      "('hordes', 'around', 'every')\n",
      "('around', 'every', 'corner')\n",
      "('every', 'corner', '.')\n",
      "('corner', '.', 'how')\n",
      "('.', 'how', 'is')\n",
      "('how', 'is', 'it')\n",
      "('is', 'it', 'cool')\n",
      "('it', 'cool', '?')\n",
      "('cool', '?', 'let')\n",
      "('?', 'let', 'me')\n",
      "('let', 'me', 'count')\n",
      "('me', 'count', 'the')\n",
      "('count', 'the', 'ways')\n",
      "('the', 'ways', '1.')\n",
      "('ways', '1.', 'zombie')\n",
      "('1.', 'zombie', 'birth')\n",
      "('zombie', 'birth', '2.')\n",
      "('birth', '2.', 'flying')\n",
      "('2.', 'flying', 'zombie')\n",
      "('flying', 'zombie', 'head')\n",
      "('zombie', 'head', '3.')\n",
      "('head', '3.', 'zombie')\n",
      "('3.', 'zombie', 'birds')\n",
      "('zombie', 'birds', '.')\n",
      "('birds', '.', '4.')\n",
      "('.', '4.', 'zombie')\n",
      "('4.', 'zombie', 'with')\n",
      "('zombie', 'with', 'no')\n",
      "('with', 'no', 'legs')\n",
      "('no', 'legs', 'swimming')\n",
      "('legs', 'swimming', 'in')\n",
      "('swimming', 'in', 'a')\n",
      "('in', 'a', 'pool')\n",
      "('a', 'pool', '.')\n",
      "('pool', '.', 'my')\n",
      "('.', 'my', 'favorite')\n",
      "('my', 'favorite', 'zombie')\n",
      "('favorite', 'zombie', 'was')\n",
      "('zombie', 'was', 'the')\n",
      "('was', 'the', 'machete-wielding')\n",
      "('the', 'machete-wielding', 'maniac')\n",
      "('machete-wielding', 'maniac', 'at')\n",
      "('maniac', 'at', 'the')\n",
      "('at', 'the', 'gas')\n",
      "('the', 'gas', 'station')\n",
      "('gas', 'station', '.')\n",
      "('station', '.', 'he')\n",
      "('.', 'he', 'was')\n",
      "('he', 'was', 'bad')\n",
      "('was', 'bad', 'ass')\n",
      "('bad', 'ass', 'and')\n",
      "('ass', 'and', 'nearly')\n",
      "('and', 'nearly', 'tore')\n",
      "('nearly', 'tore', 'down')\n",
      "('tore', 'down', 'the')\n",
      "('down', 'the', 'entire')\n",
      "('the', 'entire', 'building')\n",
      "('entire', 'building', 'trying')\n",
      "('building', 'trying', 'to')\n",
      "('trying', 'to', 'kill')\n",
      "('to', 'kill', 'a')\n",
      "('kill', 'a', 'girl.')\n",
      "('a', 'girl.', '<')\n",
      "('girl.', '<', 'br')\n",
      "('<', 'br', '/')\n",
      "('br', '/', '>')\n",
      "('/', '>', '<')\n",
      "('>', '<', 'br')\n",
      "('<', 'br', '/')\n",
      "('br', '/', '>')\n",
      "('/', '>', 'favorite')\n",
      "('>', 'favorite', 'quote')\n",
      "('favorite', 'quote', '\\x96')\n",
      "('quote', '\\x96', 'when')\n",
      "('\\x96', 'when', 'a')\n",
      "('when', 'a', 'sergeant')\n",
      "('a', 'sergeant', 'insists')\n",
      "('sergeant', 'insists', 'on')\n",
      "('insists', 'on', 'cremating')\n",
      "('on', 'cremating', 'a')\n",
      "('cremating', 'a', 'zombie')\n",
      "('a', 'zombie', ',')\n",
      "('zombie', ',', 'the')\n",
      "(',', 'the', 'scientists')\n",
      "('the', 'scientists', 'asks')\n",
      "('scientists', 'asks', ',')\n",
      "('asks', ',', '``')\n",
      "(',', '``', 'do')\n",
      "('``', 'do', \"n't\")\n",
      "('do', \"n't\", 'you')\n",
      "(\"n't\", 'you', 'think')\n",
      "('you', 'think', 'that')\n",
      "('think', 'that', 'once')\n",
      "('that', 'once', 'the')\n",
      "('once', 'the', 'ash')\n",
      "('the', 'ash', 'is')\n",
      "('ash', 'is', 'in')\n",
      "('is', 'in', 'the')\n",
      "('in', 'the', 'air')\n",
      "('the', 'air', ',')\n",
      "('air', ',', 'it')\n",
      "(',', 'it', 'will')\n",
      "('it', 'will', 'fall')\n",
      "('will', 'fall', 'to')\n",
      "('fall', 'to', 'the')\n",
      "('to', 'the', 'ground')\n",
      "('the', 'ground', ',')\n",
      "('ground', ',', 'and')\n",
      "(',', 'and', 'contaminate')\n",
      "('and', 'contaminate', 'everything')\n",
      "('contaminate', 'everything', '?')\n",
      "('everything', '?', \"''\")\n",
      "('?', \"''\", 'to')\n",
      "(\"''\", 'to', 'which')\n",
      "('to', 'which', 'the')\n",
      "('which', 'the', 'sargeant')\n",
      "('the', 'sargeant', 'boldly')\n",
      "('sargeant', 'boldly', 'replies')\n",
      "('boldly', 'replies', ',')\n",
      "('replies', ',', '``')\n",
      "(',', '``', 'now')\n",
      "('``', 'now', 'you')\n",
      "('now', 'you', \"'re\")\n",
      "('you', \"'re\", 'talking')\n",
      "(\"'re\", 'talking', 'science')\n",
      "('talking', 'science', 'fiction')\n",
      "('science', 'fiction', '.')\n",
      "('fiction', '.', \"''\")\n",
      "('.', \"''\", 'he')\n",
      "(\"''\", 'he', 'also')\n",
      "('he', 'also', 'continues')\n",
      "('also', 'continues', 'to')\n",
      "('continues', 'to', 'mention')\n",
      "('to', 'mention', 'the')\n",
      "('mention', 'the', '``')\n",
      "('the', '``', 'science')\n",
      "('``', 'science', 'fiction')\n",
      "('science', 'fiction', \"''\")\n",
      "('fiction', \"''\", 'told')\n",
      "(\"''\", 'told', 'by')\n",
      "('told', 'by', 'the')\n",
      "('by', 'the', 'scientists')\n",
      "('the', 'scientists', 'even')\n",
      "('scientists', 'even', 'at')\n",
      "('even', 'at', 'the')\n",
      "('at', 'the', 'end')\n",
      "('the', 'end', 'when')\n",
      "('end', 'when', 'everyone')\n",
      "('when', 'everyone', 'dies.')\n",
      "('everyone', 'dies.', '<')\n",
      "('dies.', '<', 'br')\n",
      "('<', 'br', '/')\n",
      "('br', '/', '>')\n",
      "('/', '>', '<')\n",
      "('>', '<', 'br')\n",
      "('<', 'br', '/')\n",
      "('br', '/', '>')\n",
      "('/', '>', 'extras')\n",
      "('>', 'extras', ':')\n",
      "('extras', ':', 'gallery')\n",
      "(':', 'gallery', ',')\n",
      "('gallery', ',', 'trailers')\n",
      "(',', 'trailers', ',')\n",
      "('trailers', ',', 'and')\n",
      "(',', 'and', 'interviews')\n",
      "('and', 'interviews', ',')\n",
      "('interviews', ',', 'most')\n",
      "(',', 'most', 'notably')\n",
      "('most', 'notably', 'the')\n",
      "('notably', 'the', 'one')\n",
      "('the', 'one', 'with')\n",
      "('one', 'with', 'mattei')\n",
      "('with', 'mattei', 'where')\n",
      "('mattei', 'where', 'he')\n",
      "('where', 'he', 'insists')\n",
      "('he', 'insists', 'he')\n",
      "('insists', 'he', 'directed')\n",
      "('he', 'directed', '40')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('directed', '40', '%')\n",
      "('40', '%', 'of')\n",
      "('%', 'of', 'the')\n",
      "('of', 'the', 'scenes')\n",
      "('the', 'scenes', ',')\n",
      "('scenes', ',', 'yet')\n",
      "(',', 'yet', 'can')\n",
      "('yet', 'can', 'not')\n",
      "('can', 'not', 'recall')\n",
      "('not', 'recall', 'which')\n",
      "('recall', 'which', 'ones')\n",
      "('which', 'ones', 'or')\n",
      "('ones', 'or', 'any')\n",
      "('or', 'any', 'other')\n",
      "('any', 'other', 'significant')\n",
      "('other', 'significant', 'details.')\n",
      "('significant', 'details.', '<')\n",
      "('details.', '<', 'br')\n",
      "('<', 'br', '/')\n",
      "('br', '/', '>')\n",
      "('/', '>', '<')\n",
      "('>', '<', 'br')\n",
      "('<', 'br', '/')\n",
      "('br', '/', '>')\n",
      "('/', '>', 'bottom')\n",
      "('>', 'bottom', 'line')\n",
      "('bottom', 'line', ':')\n",
      "('line', ':', 'a')\n",
      "(':', 'a', 'must')\n",
      "('a', 'must', 'see')\n",
      "('must', 'see', 'for')\n",
      "('see', 'for', 'zombie')\n",
      "('for', 'zombie', 'and')\n",
      "('zombie', 'and', 'fulci')\n",
      "('and', 'fulci', 'fans.')\n",
      "('fulci', 'fans.', '<')\n",
      "('fans.', '<', 'br')\n",
      "('<', 'br', '/')\n",
      "('br', '/', '>')\n",
      "('/', '>', '<')\n",
      "('>', '<', 'br')\n",
      "('<', 'br', '/')\n",
      "('br', '/', '>')\n",
      "('/', '>', 'rating')\n",
      "('>', 'rating', ':')\n",
      "('rating', ':', '7/10')\n",
      "(':', '7/10', '<')\n",
      "('7/10', '<', 'br')\n",
      "('<', 'br', '/')\n",
      "('br', '/', '>')\n",
      "('/', '>', '<')\n",
      "('>', '<', 'br')\n",
      "('<', 'br', '/')\n",
      "('br', '/', '>')\n",
      "('/', '>', 'molly')\n",
      "('>', 'molly', 'celaschi')\n",
      "('molly', 'celaschi', 'www.horroryearbook.com')\n",
      "('celaschi', 'www.horroryearbook.com', 'myspace.com/horroryearbook')\n"
     ]
    }
   ],
   "source": [
    "#Trigram\n",
    "for words in tokenized:\n",
    "    trigrams = ngrams(words, 3)\n",
    "    \n",
    "for trigram in trigrams:\n",
    "    print(trigram)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8417125",
   "metadata": {},
   "source": [
    "# Feature Generation and Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56884161",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code inspiration for tf-idf taken from colab notebook - https://colab.research.google.com/drive/1IsqqtoEVG8n21tb0tUMCN0mLqiBbgnJ8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e090336",
   "metadata": {},
   "source": [
    "**Feature 1 -- Stemming, bigrams and Applied TF-IDF**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b53ba759",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5a472b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate TF-IDF with bi-grams and \n",
    "# filter based on frequency threshold and after applying stemming\n",
    "def calculate_tfidf_ngrams_with_threshold(documents, n, threshold):\n",
    "    # Apply stemming\n",
    "    st = LancasterStemmer()\n",
    "    stemmed_documents_1 = [[' '.join([st.stem(word) for word in words])] for words in documents] #https://www.programiz.com/python-programming/methods/string/join\n",
    "\n",
    "    # Generate n-grams and calculate frequency\n",
    "    all_bigrams = []\n",
    "    for doc in stemmed_documents_1:\n",
    "        #Splitting terms in the document to words(bigrams)\n",
    "        terms = list(ngrams(doc[0].split(), n))\n",
    "        all_bigrams.extend(terms)\n",
    "\n",
    "    # Calculate the frequency of all bigrams\n",
    "    frequency_word_bigrams = nltk.FreqDist(all_bigrams)\n",
    "\n",
    "    # Filter bigrams based on the threshold\n",
    "    filtered_bigrams = {bigram: freq for bigram, freq in frequency_word_bigrams.items() if freq >= threshold}\n",
    "\n",
    "    # Create a vocabulary \n",
    "    all_terms = set(filtered_bigrams.keys())\n",
    "    vocabulary_1 = sorted(list(all_terms))\n",
    "\n",
    "    # Calculate TF - Asked ChatGPT on how to create a TF-matrix so it suggested using pd.Dataframe\n",
    "    #https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.html\n",
    "    tf_matrix = pd.DataFrame(0, index=df.index, columns=vocabulary_1, dtype=float)\n",
    "    #Iterating through index and documents \n",
    "    for i, doc in enumerate(stemmed_documents_1): #https://realpython.com/python-enumerate/\n",
    "        terms = list(ngrams(doc[0].split(), n))\n",
    "        for term in terms:\n",
    "            #counting the frequency of each term in each document.\n",
    "            #Incrementing the tf matrix by 1 if the term is in the vocabulary\n",
    "            if term in vocabulary_1:\n",
    "                tf_matrix.at[i, term] += 1\n",
    "\n",
    "    # Calculate IDF - Asked ChatGPT on how to create a IDF-vectors so it suggested using pd.Series\n",
    "    #https://pandas.pydata.org/docs/reference/api/pandas.Series.html\n",
    "    idf_vector = pd.Series(0, index=vocabulary_1, dtype=float)\n",
    "    N = len(stemmed_documents_1)\n",
    "    for term in vocabulary_1:\n",
    "        #counting the number of documents in which the bigram appears \n",
    "        df_term = sum([1 for doc in stemmed_documents_1 if term in list(ngrams(doc[0].split(), n))])\n",
    "        #Calculating the IDF value of each bigram\n",
    "        idf_vector.at[term] = math.log(N / (1 + df_term), 10)\n",
    "\n",
    "    # Calculate TF-IDF\n",
    "    tfidf_matrix_1 = tf_matrix * idf_vector\n",
    "\n",
    "    return tfidf_matrix_1, vocabulary_1\n",
    "\n",
    "# Calculate TF-IDF matrix with bigrams and filter based on frequency threshold\n",
    "tfidf_matrix_1, vocabulary_1 = calculate_tfidf_ngrams_with_threshold(df['tokenized_review'], n=2, threshold=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38638107",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5201d7d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9807371",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "137b2dbb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a247be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5c3d1eec",
   "metadata": {},
   "source": [
    "**Feature 2 -- Stemming, removed stopwords and punctuations, unigrams and TF-IDF**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e174daa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate TF-IDF after applying stemming \n",
    "# and stopwords and punctuations removal on unigrams\n",
    "def calculate_tfidf(documents):\n",
    "    # Apply stemming\n",
    "    st = LancasterStemmer()\n",
    "    stemmed_documents_2 = [[' '.join([st.stem(word) for word in words if word not in \n",
    "                                      stoplist and word not in string.punctuation])] for words in documents]\n",
    "\n",
    "\n",
    "    # Create a vocabulary \n",
    "    all_terms = set() #only unique terms are allowed \n",
    "    for doc in stemmed_documents_2:\n",
    "        all_terms.update(doc[0].split()) #.update() to add items to dictionary\n",
    "    vocabulary_2 = sorted(list(all_terms))\n",
    "\n",
    "   # Calculate TF - Asked ChatGPT on how to create a TF-matrix so it suggested using pd.Dataframe\n",
    "    tf_matrix = pd.DataFrame(0, index=df.index, columns=vocabulary_2, dtype=float)\n",
    "    #Iterating through index and document\n",
    "    for i, doc in enumerate(stemmed_documents_2): #https://realpython.com/python-enumerate/\n",
    "        #counting the frequency of each term in each document.\n",
    "        #Incrementing the tf matrix by 1 if the term is in the document\n",
    "        for term in doc[0].split():\n",
    "            tf_matrix.at[i, term] += 1   #adding to the matrix\n",
    "            \n",
    "    # Calculate IDF - Asked ChatGPT on how to create a IDF-vectors so it suggested using pd.Series\n",
    "    # https://pandas.pydata.org/docs/reference/api/pandas.Series.html\n",
    "    idf_vector = pd.Series(0, index=vocabulary_2, dtype=float)\n",
    "    N = len(stemmed_documents_2)\n",
    "    for term in vocabulary_2:\n",
    "        #counting the number of documents in which the term appears \n",
    "        df_term = sum([1 for doc in stemmed_documents_2 if term in doc[0].split()])\n",
    "        #Calculating the IDF value of each unigram\n",
    "        idf_vector.at[term] = math.log(N / (1 + df_term), 10)\n",
    "        \n",
    "\n",
    "    # Calculate TF-IDF\n",
    "    tfidf_matrix_2 = tf_matrix * idf_vector\n",
    "\n",
    "    return tfidf_matrix_2, vocabulary_2\n",
    "\n",
    "# Calculate TF-IDF matrix and get vocabulary\n",
    "tfidf_matrix_2, vocabulary_2 = calculate_tfidf(df['tokenized_review'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "736184af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c9a1510",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d2757d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c55b5d5b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfc2cf47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1666064f",
   "metadata": {},
   "source": [
    "**Feature 3 -- Lemmatization, removed stopwords and punctuations, unigrams and TF-IDF**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "106b941e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate TF-IDF after applying Lemmatization \n",
    "# and stopwords and punctuations removal on unigrams\n",
    "def calculate_tfidf(documents):\n",
    "    # Apply stemming\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lemmatized_documents_1 = [[' '.join([lemmatizer.lemmatize(word) for word in words if word not in \n",
    "                                         stoplist and word not in string.punctuation])] for words in documents]\n",
    "\n",
    "\n",
    "    # Create a vocabulary \n",
    "    all_terms = set()  #only unique terms are allowed \n",
    "    for doc in lemmatized_documents_1:\n",
    "        all_terms.update(doc[0].split()) #.update() to add items to dictionary\n",
    "    vocabulary_3 = sorted(list(all_terms))\n",
    "\n",
    "    # Calculate TF - Asked ChatGPT on how to create a TF-matrix so it suggested using pd.Dataframe\n",
    "    tf_matrix = pd.DataFrame(0, index=df.index, columns=vocabulary_3, dtype=float)\n",
    "    #Iterating through index and document\n",
    "    for i, doc in enumerate(lemmatized_documents_1):#https://realpython.com/python-enumerate/\n",
    "        #counting the frequency of each term in each document.\n",
    "        #Incrementing the tf matrix by 1 if the term is in the document\n",
    "        for term in doc[0].split():\n",
    "            tf_matrix.at[i, term] += 1 #adding to matrix\n",
    "\n",
    "    # Calculate IDF - Asked ChatGPT on how to create a IDF-vectors so it suggested using pd.Series\n",
    "    # https://pandas.pydata.org/docs/reference/api/pandas.Series.html\n",
    "    idf_vector = pd.Series(0, index=vocabulary_3, dtype=float)\n",
    "    N = len(lemmatized_documents_1)\n",
    "    for term in vocabulary_3:\n",
    "        #counting the number of documents in which the term appears \n",
    "        df_term = sum([1 for doc in lemmatized_documents_1 if term in doc[0].split()])\n",
    "        #Calculating the IDF value of each unigram\n",
    "        idf_vector.at[term] = math.log(N / (1 + df_term), 10)\n",
    "\n",
    "    # Calculate TF-IDF\n",
    "    tfidf_matrix_3 = tf_matrix * idf_vector\n",
    "\n",
    "    return tfidf_matrix_3, vocabulary_3\n",
    "\n",
    "# Calculate TF-IDF matrix and get vocabulary\n",
    "tfidf_matrix_3, vocabulary_3 = calculate_tfidf(df['tokenized_review'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf395a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ab3a15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6b87065",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd09791f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccc5fe1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "53841d16",
   "metadata": {},
   "source": [
    "# Data Splits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d923099c",
   "metadata": {},
   "source": [
    "**Split data into train, developement  and test sets with Feature 1 - Stemming, bigrams and Applied TF-IDF**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "895af90b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1, X_test1, y_train1, y_test1 = train_test_split(tfidf_matrix_1, df.labels, test_size=0.2, random_state=42)\n",
    "X_train1, X_dev1, y_train1, y_dev1 = train_test_split(X_train1, y_train1,test_size=0.2, train_size=0.8, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "382b8309",
   "metadata": {},
   "source": [
    "**Split data into train, developement and test sets with Feature 2 - Stemming, removed stopwords and punctuations, unigrams and TF-IDF**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "12c0cec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(tfidf_matrix_2, df.labels, test_size=0.2, random_state=42)\n",
    "X_train2, X_dev2, y_train2, y_dev2 = train_test_split(X_train2, y_train2,test_size=0.2, train_size=0.8, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d22f8d7",
   "metadata": {},
   "source": [
    "**Split data into train, developement and test sets with Feature 3 - Lemmatization, removed stopwords and punctuations, unigrams and TF-IDF**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "19eaa197",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train3, X_test3, y_train3, y_test3 = train_test_split(tfidf_matrix_3, df.labels, test_size=0.2, random_state=42)\n",
    "X_train3, X_dev3, y_train3, y_dev3 = train_test_split(X_train3, y_train3,test_size=0.2, train_size=0.8, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32bf5f77",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1d0cd30a",
   "metadata": {},
   "source": [
    "# Naïve Bayes - MultinomialNB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c233d04",
   "metadata": {},
   "source": [
    "**Feature 1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6abd780b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.765625\n"
     ]
    }
   ],
   "source": [
    "#Training a machine learning model (e.g., Naive Bayes) - for Feature 1\n",
    "model_1 = MultinomialNB()\n",
    "model_1.fit(X_train1, y_train1)\n",
    "model_1.predict(X_dev1)\n",
    "# Evaluate the model's performance on the dev data\n",
    "accuracy1 = model_1.score(X_dev1, y_dev1)\n",
    "print(accuracy1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b12fe6b",
   "metadata": {},
   "source": [
    "**Feature 2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c8cf1593",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.784375\n"
     ]
    }
   ],
   "source": [
    "# Training a machine learning model (e.g., Naive Bayes) - for Feature 2\n",
    "model_2 = MultinomialNB()\n",
    "model_2.fit(X_train2, y_train2)\n",
    "model_2.predict(X_dev2)\n",
    "# Evaluating the model's performance on the dev data\n",
    "accuracy2 = model_2.score(X_dev2, y_dev2)\n",
    "print(accuracy2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cc6099f",
   "metadata": {},
   "source": [
    "**Feature 3**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6680e597",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7859375\n"
     ]
    }
   ],
   "source": [
    "# Training a machine learning model (e.g., Naive Bayes) - for Feature 3\n",
    "model_3 = MultinomialNB()\n",
    "model_3.fit(X_train3, y_train3)\n",
    "\n",
    "# Evaluating the model's performance on the dev data\n",
    "model_3.predict(X_dev3)\n",
    "accuracy3 = model_3.score(X_dev3, y_dev3)\n",
    "print(accuracy3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c45f3cdc",
   "metadata": {},
   "source": [
    "**Evaluating the Test Set with the model which gave higher accracy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0c5b2c0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.77875\n",
      "Confusion matrix: \n",
      " [[308  70]\n",
      " [107 315]]\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.81      0.78       378\n",
      "           1       0.82      0.75      0.78       422\n",
      "\n",
      "    accuracy                           0.78       800\n",
      "   macro avg       0.78      0.78      0.78       800\n",
      "weighted avg       0.78      0.78      0.78       800\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "# Evaluating on test set\n",
    "predictions = model_3.predict(X_test3)\n",
    "\n",
    "print('Accuracy:',accuracy_score(y_test3,predictions))\n",
    "print('Confusion matrix:','\\n',confusion_matrix(y_test3,predictions))\n",
    "print('Classification Report:','\\n',classification_report(y_test3,predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb48e48a",
   "metadata": {},
   "source": [
    "# Naïve Bayes - from Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52219f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code adapted from - https://blog.devgenius.io/implementing-na%C3%AFve-bayes-classification-from-scratch-with-python-badd5a9be9c3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "35cf7db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Train the Naive Bayes model\n",
    "def train_naive_bayes(X_train, y_train):\n",
    "    # Calculate class priors\n",
    "    prior = {}\n",
    "    classes, counts = np.unique(y_train, return_counts=True)\n",
    "    #calculate P(class) = count(class 0 or 1)/total number of values in the class\n",
    "    #Prior probability\n",
    "    for class_0_1, count in zip(classes, counts):\n",
    "        prior[class_0_1] = count / len(y_train)\n",
    "    \n",
    "    # Calculate means and variances for each feature in each class\n",
    "    means = {}\n",
    "    var = {}\n",
    "    \n",
    "    #Taking feature of each of the class - (x)\n",
    "    for cls in classes:\n",
    "        class_indices = [i for i in range(len(y_train_encoded)) if y_train_encoded[i] == cls]\n",
    "        #https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.iloc.html\n",
    "        class_data = X_train.iloc[class_indices] #Access the  feature of a particular class using iloc\n",
    "\n",
    "        class_means = np.mean(class_data, axis=0)\n",
    "        class_var = np.var(class_data, axis=0)\n",
    "\n",
    "        means[cls] = class_means\n",
    "        var[cls] = class_var\n",
    "    \n",
    "    return prior, means, var\n",
    "\n",
    "\n",
    "#Gaussian Distribution\n",
    "def Normal(n, mu, var):\n",
    "    sd = np.sqrt(var)\n",
    "     # Check if standard deviation is zero\n",
    "    if sd == 0:\n",
    "        return np.zeros_like(n)  # Return an array of zeros to avoid division by zero\n",
    "\n",
    "    pdf = (np.e ** (-0.5 * ((n - mu)/sd) ** 2)) / (sd * np.sqrt(2 * np.pi))\n",
    "    return pdf\n",
    "\n",
    "\n",
    "# Prediction of Naive Bayes \n",
    "def predict_naive_bayes(X, prior, means, var):\n",
    "    classes = list(prior.keys())\n",
    "    predictions = []\n",
    "    \n",
    "    # calculate P(reviews|class)\n",
    "    for i in range(len(X)):\n",
    "        class_likelihoods = []\n",
    "\n",
    "        for cls in classes:\n",
    "            feature_likelihoods = []\n",
    "            # log-prior - P(class)\n",
    "            feature_likelihoods.append(np.log(prior[cls]))\n",
    "\n",
    "            for j in range(X.shape[1]):  # Use shape[1] to iterate over features\n",
    "                data = X.iloc[i, j]  # Access the j-th feature of the i-th sample using iloc\n",
    "                mean = means[cls][j]\n",
    "                variance = var[cls][j]\n",
    "                #likelihoods - p(reviews1|class) + p(reviews2|class) + ... + p(reviewsN|class)|P(class)\n",
    "                likelihood = Normal(data, mean, variance)\n",
    "                # log-Likelihood\n",
    "                if likelihood != 0:\n",
    "                    likelihood = np.log(likelihood)\n",
    "                else:\n",
    "                    likelihood = 1 / X.shape[1]  # Adjust the handling of zero likelihood\n",
    "\n",
    "                feature_likelihoods.append(likelihood)\n",
    "            \n",
    "            total_likelihood = sum(feature_likelihoods)\n",
    "            # Calculate posterior - P(class|reviews)\n",
    "            class_likelihoods.append(total_likelihood)\n",
    "\n",
    "        # Take class with max log-likelihood\n",
    "        max_index = class_likelihoods.index(max(class_likelihoods))\n",
    "        prediction = classes[max_index]\n",
    "        predictions.append(prediction)\n",
    "\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d6ac0ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "720b8efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83d69180",
   "metadata": {},
   "source": [
    "**Feature 1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0c34bdc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Development Set Accuracy1: 0.728125\n"
     ]
    }
   ],
   "source": [
    "# Encode class labels\n",
    "y_train_encoded = label_encoder.fit_transform(y_train1)\n",
    "y_dev_encoded = label_encoder.transform(y_dev1)\n",
    "y_test_encoded = label_encoder.transform(y_test1)\n",
    "\n",
    "#Calculate prior, mean and variance of trainset\n",
    "prior, means, var = train_naive_bayes(X_train1, y_train_encoded)\n",
    "\n",
    "# Make predictions on the development set\n",
    "dev_predictions = predict_naive_bayes(X_dev1, prior, means, var)\n",
    "\n",
    "# Evaluate the model on the development set\n",
    "dev_accuracy = accuracy_score(y_dev_encoded , dev_predictions)\n",
    "print(f\"Development Set Accuracy1: {dev_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5731324a",
   "metadata": {},
   "source": [
    "**Feature 2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "55facd22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Development Set Accuracy2: 0.55\n"
     ]
    }
   ],
   "source": [
    "# Encode class labels\n",
    "y_train_encoded = label_encoder.fit_transform(y_train2)\n",
    "y_dev_encoded = label_encoder.transform(y_dev2)\n",
    "y_test_encoded = label_encoder.transform(y_test2)\n",
    "\n",
    "#Calculate prior, mean and variance of trainset\n",
    "prior, means, var = train_naive_bayes(X_train2, y_train_encoded)\n",
    "\n",
    "# Make predictions on the development set\n",
    "dev_predictions = predict_naive_bayes(X_dev2, prior, means, var)\n",
    "\n",
    "# Evaluate the model on the development set\n",
    "dev_accuracy = accuracy_score(y_dev_encoded , dev_predictions)\n",
    "print(f\"Development Set Accuracy2: {dev_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "684ad163",
   "metadata": {},
   "source": [
    "**Feature 3**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e260f168",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Development Set Accuracy3: 0.571875\n"
     ]
    }
   ],
   "source": [
    "# Encode class labels\n",
    "y_train_encoded = label_encoder.fit_transform(y_train3)\n",
    "y_dev_encoded = label_encoder.transform(y_dev3)\n",
    "y_test_encoded = label_encoder.transform(y_test3)\n",
    "\n",
    "#Calculate prior, mean and variance of trainset\n",
    "prior, means, var = train_naive_bayes(X_train3, y_train_encoded)\n",
    "\n",
    "# Make predictions on the development set\n",
    "dev_predictions = predict_naive_bayes(X_dev3, prior, means, var)\n",
    "\n",
    "# Evaluate the model on the development set\n",
    "dev_accuracy = accuracy_score(y_dev_encoded , dev_predictions)\n",
    "print(f\"Development Set Accuracy3: {dev_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d39121bb",
   "metadata": {},
   "source": [
    "**Evaluating the Test Set with the model which gave higher accracy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "47a1216f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.71375\n",
      "Confusion matrix: \n",
      " [[254 124]\n",
      " [105 317]]\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.67      0.69       378\n",
      "           1       0.72      0.75      0.73       422\n",
      "\n",
      "    accuracy                           0.71       800\n",
      "   macro avg       0.71      0.71      0.71       800\n",
      "weighted avg       0.71      0.71      0.71       800\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "y_test_encoded = label_encoder.transform(y_test1)\n",
    "# Evaluating on test set\n",
    "prior, means, var = train_naive_bayes(X_train1, y_train_encoded)\n",
    "test_predictions = predict_naive_bayes(X_test1, prior, means, var)\n",
    "\n",
    "\n",
    "print('Accuracy:',accuracy_score(y_test_encoded,test_predictions))\n",
    "print('Confusion matrix:','\\n',confusion_matrix(y_test_encoded,test_predictions))\n",
    "print('Classification Report:','\\n',classification_report(y_test_encoded,test_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c54f23",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "04ad02a7",
   "metadata": {},
   "source": [
    "# Logistic Regression and SVMs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57c097b8",
   "metadata": {},
   "source": [
    "**1. Logistic Regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b4a1ed28",
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------Logistic Regression (https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d0d63bf",
   "metadata": {},
   "source": [
    "**Feature 1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bb3dd149",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for Dev1: 0.6984375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "log_reg_1 = LogisticRegression(penalty='l2',dual=False, tol=0.0001, \n",
    "                                       C=1.0, fit_intercept=True, \n",
    "                                       intercept_scaling=1, \n",
    "                                       class_weight=None, random_state=None, \n",
    "                                       solver='lbfgs', max_iter=100, \n",
    "                                       multi_class='auto', verbose=0, \n",
    "                                       warm_start=False, n_jobs=None, l1_ratio=None)\n",
    "log_reg_1.fit(X_train1, y_train1)\n",
    "log_reg_1.predict(X_dev1)\n",
    "score1 = log_reg_1.score(X_dev1, y_dev1)\n",
    "print(f\"Accuracy for Dev1: {score1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cb4adc5",
   "metadata": {},
   "source": [
    "**Feature 2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "36519eb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for Dev2: 0.8703125\n"
     ]
    }
   ],
   "source": [
    "log_reg_2 = LogisticRegression(penalty='l2',dual=False, tol=0.0001, \n",
    "                                       C=1.0, fit_intercept=True, \n",
    "                                       intercept_scaling=1, \n",
    "                                       class_weight=None, random_state=None, \n",
    "                                       solver='lbfgs', max_iter=100, \n",
    "                                       multi_class='auto', verbose=0, \n",
    "                                       warm_start=False, n_jobs=None, l1_ratio=None)\n",
    "log_reg_2.fit(X_train2, y_train2)\n",
    "log_reg_2.predict(X_dev2)\n",
    "score2 = log_reg_2.score(X_dev2, y_dev2)\n",
    "print(f\"Accuracy for Dev2: {score2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf088fcf",
   "metadata": {},
   "source": [
    "**Feature 3**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c0339703",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for Dev3: 0.8546875\n"
     ]
    }
   ],
   "source": [
    "log_reg_3 = LogisticRegression(penalty='l2',dual=False, tol=0.0001, \n",
    "                                       C=1.0, fit_intercept=True, \n",
    "                                       intercept_scaling=1, \n",
    "                                       class_weight=None, random_state=None, \n",
    "                                       solver='lbfgs', max_iter=100, \n",
    "                                       multi_class='auto', verbose=0, \n",
    "                                       warm_start=False, n_jobs=None, l1_ratio=None)\n",
    "log_reg_3.fit(X_train3, y_train3)\n",
    "log_reg_3.predict(X_dev3)\n",
    "score3 = log_reg_3.score(X_dev3, y_dev3)\n",
    "print(f\"Accuracy for Dev3: {score3}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d7ab8f7",
   "metadata": {},
   "source": [
    "**Evaluating the Test Set with the model which gave higher accracy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "14cfefa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.84125\n",
      "Confusion matrix: \n",
      " [[314  64]\n",
      " [ 63 359]]\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.83      0.83       378\n",
      "           1       0.85      0.85      0.85       422\n",
      "\n",
      "    accuracy                           0.84       800\n",
      "   macro avg       0.84      0.84      0.84       800\n",
      "weighted avg       0.84      0.84      0.84       800\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "# Evaluating on test set\n",
    "predictions = log_reg_2.predict(X_test2)\n",
    "\n",
    "print('Accuracy:',accuracy_score(y_test2,predictions))\n",
    "print('Confusion matrix:','\\n',confusion_matrix(y_test2,predictions))\n",
    "print('Classification Report:','\\n',classification_report(y_test2,predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba67538d",
   "metadata": {},
   "source": [
    "**2. Support Vector Machines (SVC)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d3177e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------SVM (https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9ba3327",
   "metadata": {},
   "source": [
    "**Feature 1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "72c1474d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for Dev1: 0.7453125\n"
     ]
    }
   ],
   "source": [
    "svm_clf_1 = SVC(C=1.0, kernel='rbf', \n",
    "                degree=3, gamma='scale', \n",
    "                coef0=0.0, shrinking=True, \n",
    "                probability=False, tol=0.001, \n",
    "                cache_size=200, class_weight=None, \n",
    "                verbose=False, max_iter=-1, \n",
    "                decision_function_shape='ovr', \n",
    "                break_ties=False, random_state=None)\n",
    "\n",
    "svm_clf_1.fit(X_train1, y_train1)\n",
    "svm_clf_1.predict(X_dev1)\n",
    "score1 = svm_clf_1.score(X_dev1, y_dev1)\n",
    "print(f\"Accuracy for Dev1: {score1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32f979d4",
   "metadata": {},
   "source": [
    "**Feature 2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5e426516",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for Dev2: 0.8375\n"
     ]
    }
   ],
   "source": [
    "svm_clf_2 = SVC(C=1.0, kernel='rbf', \n",
    "                degree=3, gamma='scale', \n",
    "                coef0=0.0, shrinking=True, \n",
    "                probability=False, tol=0.001, \n",
    "                cache_size=200, class_weight=None, \n",
    "                verbose=False, max_iter=-1, \n",
    "                decision_function_shape='ovr', \n",
    "                break_ties=False, random_state=None)\n",
    "\n",
    "svm_clf_2.fit(X_train2, y_train2)\n",
    "svm_clf_2.predict(X_dev2)\n",
    "score2 = svm_clf_2.score(X_dev2, y_dev2)\n",
    "print(f\"Accuracy for Dev2: {score2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2fce982",
   "metadata": {},
   "source": [
    "**Feature 3**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a03f34ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for Dev3: 0.8375\n"
     ]
    }
   ],
   "source": [
    "svm_clf_3 = SVC(C=1.0, kernel='rbf', \n",
    "                degree=3, gamma='scale', \n",
    "                coef0=0.0, shrinking=True, \n",
    "                probability=False, tol=0.001, \n",
    "                cache_size=200, class_weight=None, \n",
    "                verbose=False, max_iter=-1, \n",
    "                decision_function_shape='ovr', \n",
    "                break_ties=False, random_state=None)\n",
    "\n",
    "svm_clf_3.fit(X_train3, y_train3)\n",
    "svm_clf_3.predict(X_dev3)\n",
    "score3 = svm_clf_3.score(X_dev3, y_dev3)\n",
    "print(f\"Accuracy for Dev3: {score3}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18bb383c",
   "metadata": {},
   "source": [
    "**Evaluating the Test Set with the model which gave higher accracy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "18bcb226",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.805\n",
      "Confusion matrix: \n",
      " [[265 113]\n",
      " [ 43 379]]\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.70      0.77       378\n",
      "           1       0.77      0.90      0.83       422\n",
      "\n",
      "    accuracy                           0.81       800\n",
      "   macro avg       0.82      0.80      0.80       800\n",
      "weighted avg       0.81      0.81      0.80       800\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "# Now apply those above metrics to evaluate your model\n",
    "predictions = svm_clf_3.predict(X_test3)\n",
    "\n",
    "print('Accuracy:',accuracy_score(y_test3,predictions))\n",
    "print('Confusion matrix:','\\n',confusion_matrix(y_test3,predictions))\n",
    "print('Classification Report:','\\n',classification_report(y_test3,predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1d4105f",
   "metadata": {},
   "source": [
    "**3. Hyperparameter Optimisation**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48e4bacf",
   "metadata": {},
   "source": [
    "**Hyperparameter Optimisation - Logistic Regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec3801a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "66888951",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]Accuracy for Dev2: 0.846875\n"
     ]
    }
   ],
   "source": [
    "#penalty=l1, class_weight='balanced',max_iter=1000, solver='liblinear', verbose=5\n",
    "log_reg_4 = LogisticRegression(penalty='l1',dual=False, tol=0.0001, \n",
    "                                       C=1.0, fit_intercept=True, \n",
    "                                       intercept_scaling=1, \n",
    "                                       class_weight='balanced', random_state=None, \n",
    "                                       solver='liblinear', max_iter=1000, \n",
    "                                       multi_class='auto', verbose=5, \n",
    "                                       warm_start=False, n_jobs=None, l1_ratio=None)\n",
    "log_reg_4.fit(X_train2, y_train2)\n",
    "log_reg_4.predict(X_dev2)\n",
    "score4 = log_reg_4.score(X_dev2, y_dev2)\n",
    "print(f\"Accuracy for Dev2: {score4}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "005fbacf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for Dev2: 0.8671875\n"
     ]
    }
   ],
   "source": [
    "#penalty=l2, class_weight='balanced',max_iter=1000, solver='lbfgs',multi_class='multinomial',l1_ratio=None\n",
    "log_reg_5 = LogisticRegression(penalty='l2',dual=False, tol=0.0001, \n",
    "                                       C=1.0, fit_intercept=True, \n",
    "                                       intercept_scaling=1, \n",
    "                                       class_weight='balanced', random_state=None, \n",
    "                                       solver='lbfgs', max_iter=1000, \n",
    "                                       multi_class='multinomial', verbose=0, \n",
    "                                       warm_start=False, n_jobs=None, l1_ratio=None)\n",
    "log_reg_5.fit(X_train2, y_train2)\n",
    "log_reg_5.predict(X_dev2)\n",
    "score5 = log_reg_5.score(X_dev2, y_dev2)\n",
    "print(f\"Accuracy for Dev2: {score5}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7a56ee9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for Dev2: 0.8703125\n"
     ]
    }
   ],
   "source": [
    "#penalty=l2, class_weight='dict',max_iter=100, solver='lbfgs',multi_class='auto',l1_ratio=None\n",
    "log_reg_6 = LogisticRegression(penalty= 'l2' ,dual=False, tol=0.0001, \n",
    "                                       C=1.0, fit_intercept=True, \n",
    "                                       intercept_scaling=1, \n",
    "                                       class_weight='dict', random_state=None, \n",
    "                                       solver='lbfgs', max_iter=100, \n",
    "                                       multi_class='auto', verbose=0, \n",
    "                                       warm_start=False, n_jobs=None, l1_ratio=None)\n",
    "log_reg_6.fit(X_train2, y_train2)\n",
    "log_reg_6.predict(X_dev2)\n",
    "score6 = log_reg_6.score(X_dev2, y_dev2)\n",
    "print(f\"Accuracy for Dev2: {score6}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f89361e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]Accuracy for Dev2: 0.875\n"
     ]
    }
   ],
   "source": [
    "#penalty=l2, class_weight=None ,max_iter=10000, solver='liblinear', verbose=10\n",
    "log_reg_7 = LogisticRegression(penalty='l2',dual=False, tol=0.0001, \n",
    "                                       C=1.0, fit_intercept=True, \n",
    "                                       intercept_scaling=1, \n",
    "                                       class_weight= None, random_state=None, \n",
    "                                       solver='liblinear', max_iter=10000, \n",
    "                                       multi_class='auto', verbose=10, \n",
    "                                       warm_start=False, n_jobs=None, l1_ratio=None)\n",
    "log_reg_7.fit(X_train2, y_train2)\n",
    "log_reg_7.predict(X_dev2)\n",
    "score7 = log_reg_7.score(X_dev2, y_dev2)\n",
    "print(f\"Accuracy for Dev2: {score7}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4aaedb25",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_iter reached after 110 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  1.8min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  1.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for Dev2: 0.88125\n"
     ]
    }
   ],
   "source": [
    "#penalty=l2, class_weight='balanced',max_iter=100, solver='sag',random_state=42\n",
    "log_reg_8 = LogisticRegression(penalty='l2',dual=False, tol=0.0001, \n",
    "                                       C=1.0, fit_intercept=True, \n",
    "                                       intercept_scaling=1, \n",
    "                                       class_weight='balanced', random_state=42, \n",
    "                                       solver='sag', max_iter=100, \n",
    "                                       multi_class='auto', verbose=10, \n",
    "                                       warm_start=False, n_jobs=None, l1_ratio=None)\n",
    "log_reg_8.fit(X_train2, y_train2)\n",
    "log_reg_8.predict(X_dev2)\n",
    "score8 = log_reg_8.score(X_dev2, y_dev2)\n",
    "print(f\"Accuracy for Dev2: {score8}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cdf7ad4",
   "metadata": {},
   "source": [
    "**Evaluation of the best Hyperparameter - Logistic Regression on the Test set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "341dc5e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.83375\n",
      "Confusion matrix: \n",
      " [[310  68]\n",
      " [ 65 357]]\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.82      0.82       378\n",
      "           1       0.84      0.85      0.84       422\n",
      "\n",
      "    accuracy                           0.83       800\n",
      "   macro avg       0.83      0.83      0.83       800\n",
      "weighted avg       0.83      0.83      0.83       800\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#penalty=l2, class_weight='balanced',max_iter=100, solver='sag',random_state=42\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "# Now apply those above metrics to evaluate your model\n",
    "predictions = log_reg_8.predict(X_test2)\n",
    "\n",
    "print('Accuracy:',accuracy_score(y_test2,predictions))\n",
    "print('Confusion matrix:','\\n',confusion_matrix(y_test2,predictions))\n",
    "print('Classification Report:','\\n',classification_report(y_test2,predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41a08d01",
   "metadata": {},
   "source": [
    "**Hyperparameter Optimisation - SVCs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "76cc8434",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for Dev3: 0.4859375\n"
     ]
    }
   ],
   "source": [
    "#Kernel = 'Poly', gamma = auto, coef0 = 0.1, \n",
    "#class_weight='balanced', decision_function_shape='ovo',\n",
    "#random_state=42\n",
    "svm_clf_4 = SVC(C=1.0, kernel='poly', \n",
    "                degree=3, gamma='auto', \n",
    "                coef0=0.1, shrinking=True, \n",
    "                probability=False, tol=0.001, \n",
    "                cache_size=200, class_weight='balanced', \n",
    "                verbose=False, max_iter=-1, \n",
    "                decision_function_shape='ovo', \n",
    "                break_ties=False, random_state=42)\n",
    "\n",
    "svm_clf_4.fit(X_train3, y_train3)\n",
    "svm_clf_4.predict(X_dev3)\n",
    "score4 = svm_clf_4.score(X_dev3, y_dev3)\n",
    "print(f\"Accuracy for Dev3: {score4}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "37d78e1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for Dev3: 0.85625\n"
     ]
    }
   ],
   "source": [
    "#kernel='sigmoid', gamma='scale', coef0 = 0.1, \n",
    "#class_weight= None, decision_function_shape='ovo',\n",
    "#random_state=42\n",
    "svm_clf_5 = SVC(C=1.0, kernel='sigmoid', \n",
    "                degree=3, gamma='scale', \n",
    "                coef0=0.1, shrinking=True, \n",
    "                probability=False, tol=0.001, \n",
    "                cache_size=200, class_weight= None, \n",
    "                verbose=False, max_iter=-1, \n",
    "                decision_function_shape='ovo', \n",
    "                break_ties=False, random_state=42)\n",
    "\n",
    "svm_clf_5.fit(X_train3, y_train3)\n",
    "svm_clf_5.predict(X_dev3)\n",
    "score5 = svm_clf_5.score(X_dev3, y_dev3)\n",
    "print(f\"Accuracy for Dev3: {score5}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "336b8ac0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for Dev3: 0.515625\n"
     ]
    }
   ],
   "source": [
    "#Kernel = 'rbf', gamma = auto, coef0 = 0.1, \n",
    "#class_weight='balanced', decision_function_shape='ovo',\n",
    "#random_state=42\n",
    "svm_clf_6 = SVC(C=1.0, kernel='rbf', \n",
    "                degree=3, gamma='auto', \n",
    "                coef0=0.1, shrinking=True, \n",
    "                probability=False, tol=0.001, \n",
    "                cache_size=200, class_weight='balanced', \n",
    "                verbose=False, max_iter=-1, \n",
    "                decision_function_shape='ovo', \n",
    "                break_ties=False, random_state=42)\n",
    "\n",
    "svm_clf_6.fit(X_train3, y_train3)\n",
    "svm_clf_6.predict(X_dev3)\n",
    "score6 = svm_clf_6.score(X_dev3, y_dev3)\n",
    "print(f\"Accuracy for Dev3: {score6}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2d1933cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for Dev3: 0.853125\n"
     ]
    }
   ],
   "source": [
    "#Kernel = 'sigmoid', gamma = scale, coef0 = 0.1, \n",
    "#class_weight='balanced', decision_function_shape='ovr',\n",
    "#random_state=42\n",
    "svm_clf_7 = SVC(C=1.0, kernel='sigmoid', \n",
    "                degree=3, gamma='scale', \n",
    "                coef0=0.1, shrinking=True, \n",
    "                probability=False, tol=0.001, \n",
    "                cache_size=200, class_weight='balanced', \n",
    "                verbose=False, max_iter=-1, \n",
    "                decision_function_shape='ovr', \n",
    "                break_ties=False, random_state=42)\n",
    "\n",
    "svm_clf_7.fit(X_train3, y_train3)\n",
    "svm_clf_7.predict(X_dev3)\n",
    "score7 = svm_clf_7.score(X_dev3, y_dev3)\n",
    "print(f\"Accuracy for Dev3: {score7}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1cd86acf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for Dev3: 0.540625\n"
     ]
    }
   ],
   "source": [
    "#Kernel = 'poly', gamma = scale, coef0 = 0.1, \n",
    "#class_weight='balanced', decision_function_shape='ovr',\n",
    "#random_state=None\n",
    "svm_clf_8 = SVC(C=1.0, kernel='poly', \n",
    "                degree=3, gamma='scale', \n",
    "                coef0=0.1, shrinking=True, \n",
    "                probability=False, tol=0.001, \n",
    "                cache_size=200, class_weight='balanced', \n",
    "                verbose=False, max_iter=-1, \n",
    "                decision_function_shape='ovr', \n",
    "                break_ties=False, random_state=None)\n",
    "\n",
    "svm_clf_8.fit(X_train3, y_train3)\n",
    "svm_clf_8.predict(X_dev3)\n",
    "score8 = svm_clf_8.score(X_dev3, y_dev3)\n",
    "print(f\"Accuracy for Dev3: {score8}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "297b3a4f",
   "metadata": {},
   "source": [
    "**Evaluation of the best Hyperparameter - SVC on the Test set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "55d01d2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.83625\n",
      "Confusion matrix: \n",
      " [[305  73]\n",
      " [ 58 364]]\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.81      0.82       378\n",
      "           1       0.83      0.86      0.85       422\n",
      "\n",
      "    accuracy                           0.84       800\n",
      "   macro avg       0.84      0.83      0.84       800\n",
      "weighted avg       0.84      0.84      0.84       800\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#kernel='sigmoid', gamma='scale', coef0 = 0.1, \n",
    "#class_weight= None, decision_function_shape='ovo',\n",
    "#random_state=42\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "# Now apply those above metrics to evaluate your model\n",
    "predictions = svm_clf_5.predict(X_test3)\n",
    "\n",
    "print('Accuracy:',accuracy_score(y_test3,predictions))\n",
    "print('Confusion matrix:','\\n',confusion_matrix(y_test3,predictions))\n",
    "print('Classification Report:','\\n',classification_report(y_test3,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b530df12",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
